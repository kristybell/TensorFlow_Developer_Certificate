{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_neural_network_regression_with_tensorflow_video.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1CGaq0o3KC43GQQQP4bsqoTJtvCtyOpYK",
      "authorship_tag": "ABX9TyM3HRTP7T7aEbPj807JsY0E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kristybell/TensorFlow_Developer_Certificate/blob/main/01_neural_network_regression_with_tensorflow_video.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction to Regression with Neural Networks in TensorFlow\n",
        "\n",
        "Ther are many definitions for a regression problem, but let's simplify it: predicting a numerical variable absed on some other combination of variable...aka predicting a number."
      ],
      "metadata": {
        "id": "9m_SMaOdwUcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg1YN7GZxacI",
        "outputId": "92dd7d04-653a-4b2d-d32f-3d08172dc53e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Data to View and Fit"
      ],
      "metadata": {
        "id": "q6i5rU4lxklJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create Features (Inependent Variable)\n",
        "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
        "\n",
        "# Create Labels (Dependent Variables)\n",
        "y = np.array([3.0, 6.0, 9.0, 12.0, 15.0, 18.0, 21.0, 24.0])\n",
        "\n",
        "# Visualize It\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "eitOUdQixr3L",
        "outputId": "beaaf5b9-c301-4283-e509-b2a92fb2a5b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the relationship between Y and y\n",
        "y == X + 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIsPa_i-yT4_",
        "outputId": "6de5433c-9dee-4f6d-e039-794d3a671a2e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inputs and Output Shapes"
      ],
      "metadata": {
        "id": "OR5divlNyr4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a demo tensor for the housing price prediction problem\n",
        "house_info = tf.constant([\"bedroom \", \"bathroom\", \"garage\"])\n",
        "house_price = tf.constant([939700])\n",
        "house_info, house_price"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyrfbxzJBahZ",
        "outputId": "d46df1ad-cf8b-41c5-90b5-e7b1fd2ad9fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom ', b'bathroom', b'garage'], dtype=object)>,\n",
              " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmUhEwNKCKUW",
        "outputId": "9d3479f2-81ad-427f-ac57-9b4ec6fee2c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-e9QA0uYBvCX",
        "outputId": "28e5169a-4a84-4bd1-92ea-98678c00dd91"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((), ())"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0].ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QM3WWNivB9_n",
        "outputId": "5b22ecb6-ca01-4255-8b97-66c69605a159"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[0], y[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYjqHqwHCZBB",
        "outputId": "8d6f23af-8c99-480f-cf21-bcd9e7273a25"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-7.0, 3.0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn NumPy arrays into tensors\n",
        "X = tf.constant(X)\n",
        "y =tf.constant(y)\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvtrGC2cCba_",
        "outputId": "7c1bc637-a7ec-4d8d-aef3-c9a8e2c825a9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = X[0].shape\n",
        "output_shape = y[0].shape\n",
        "input_shape, output_shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1tMMKRDAMV",
        "outputId": "7fb2f549-b024-4706-9b4c-fe0a18da8002"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([]), TensorShape([]))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(X,y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "akLo1th1DGdW",
        "outputId": "2a27e364-74a7-457f-bb22-f5be0baf0770"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps in Modelling in TensorFlow\n",
        "\n",
        "1. **Creating a Model** - define the input and output layers, as well as, the hidden layers of a deep learning model.\n",
        "2. **Compiling a Model** - define the loss function (the function which tells the model how wrong it is), the optimizer (tells the model how to improve the patterns its learning), and evaluation metrics (what can be used to interpret the performance of the model).\n",
        "3. **Fitting a Model** - letting the model try to find patterns between X and y (features and labels, respectively)."
      ],
      "metadata": {
        "id": "0kwvumVDDxnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)    # allows for reproducibility\n",
        "\n",
        "# 1. Create a model using the Sequential API (groups linear)\n",
        "model = tf.keras.Sequential(\n",
        "    tf.keras.layers.Dense(1)\n",
        ")\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss=tf.keras.losses.mae,              # mae --> mean absolute error (comparison of predicted vs observed)\n",
        "              optimizer = tf.keras.optimizers.SGD(),     # SGD --> stochastic gradient descent \n",
        "              metrics = [\"mae\"]\n",
        "            )    \n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=5)     # epochs --> training iterations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJtbSUgSEYNt",
        "outputId": "1f35ea38-566a-45c1-8a99-820c95074f3a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1/1 [==============================] - 1s 544ms/step - loss: 11.5048 - mae: 11.5048\n",
            "Epoch 2/5\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3723 - mae: 11.3723\n",
            "Epoch 3/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.2398 - mae: 11.2398\n",
            "Epoch 4/5\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1073 - mae: 11.1073\n",
            "Epoch 5/5\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.9748 - mae: 10.9748\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4986508f10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definitions:\n",
        "* **loss** --> how wrong the model's predictions are compared to the truth labels (objective is to minimize this metric.\n",
        "* **optimizer** --> how the model should update its internal patterns to better its predictions.\n",
        "* **mae** --> Mean Absolute Error; human interpretable values for how well the model is doing (evaluation metric)\n",
        "* **epochs** --> how many times the model will go through all of the training examples"
      ],
      "metadata": {
        "id": "H1dbLgk87m8O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out X and y\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4Or4zyH8gLF",
        "outputId": "90fddc95-1a99-4556-cb09-9aa7036baff8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try and make a prediction using our model\n",
        "y_pred = model.predict([17.0])\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyXMKGq88p-t",
        "outputId": "807d6bc3-53b8-496f-8efb-a2c19dc238d4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.716021]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred + 11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atAnWiwN8_F9",
        "outputId": "60b9890a-de6e-4874-b6e7-d90b0eef4c8d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[23.71602]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Improving the Model\n",
        "\n",
        "Can improve the model by altering the steps taken to create the model.\n",
        "\n",
        "1. **Creating a Model** \n",
        "  * add more layers\n",
        "  * increase the number of hidden units (aka neurons) within each of the hidden layers\n",
        "  * change the activation of each layers\n",
        "\n",
        "2.  **Compiling the Model**\n",
        "  * change the optimization function or the learning rate of optimization function\n",
        "\n",
        "\n",
        "3.  **Fitting the Model** \n",
        "  * fit a model with more **epochs** (allow it to train longer) or on more data (give the model more examples to learn from)"
      ],
      "metadata": {
        "id": "Gs1qeEdm9AKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rebuild the model\n",
        "\n",
        "# 1. Create the model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model (this time train for longer)\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0sFRbJf9MxZ",
        "outputId": "8fa4f6c9-40ff-4193-909c-6f96e1958d92"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 323ms/step - loss: 11.2219 - mae: 11.2219\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.0894 - mae: 11.0894\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.9569 - mae: 10.9569\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.8244 - mae: 10.8244\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.6919 - mae: 10.6919\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.5594 - mae: 10.5594\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.4269 - mae: 10.4269\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.2944 - mae: 10.2944\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 10.1619 - mae: 10.1619\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.0294 - mae: 10.0294\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.8969 - mae: 9.8969\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.7644 - mae: 9.7644\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.6319 - mae: 9.6319\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.4994 - mae: 9.4994\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3669 - mae: 9.3669\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.2344 - mae: 9.2344\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1019 - mae: 9.1019\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.9694 - mae: 8.9694\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.8369 - mae: 8.8369\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.7044 - mae: 8.7044\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.5719 - mae: 8.5719\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.4394 - mae: 8.4394\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3069 - mae: 8.3069\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1744 - mae: 8.1744\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0419 - mae: 8.0419\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.9094 - mae: 7.9094\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7769 - mae: 7.7769\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6444 - mae: 7.6444\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5119 - mae: 7.5119\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 7.3794 - mae: 7.3794\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2750 - mae: 7.2750\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 7.2694 - mae: 7.2694\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2638 - mae: 7.2638\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2581 - mae: 7.2581\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2525 - mae: 7.2525\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2469 - mae: 7.2469\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2412 - mae: 7.2412\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 7.2356 - mae: 7.2356\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2300 - mae: 7.2300\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2244 - mae: 7.2244\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.2188 - mae: 7.2188\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2131 - mae: 7.2131\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2075 - mae: 7.2075\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2019 - mae: 7.2019\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1962 - mae: 7.1962\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1906 - mae: 7.1906\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.1850 - mae: 7.1850\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1794 - mae: 7.1794\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1737 - mae: 7.1737\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1681 - mae: 7.1681\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1625 - mae: 7.1625\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1569 - mae: 7.1569\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.1512 - mae: 7.1512\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1456 - mae: 7.1456\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1400 - mae: 7.1400\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1344 - mae: 7.1344\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 7.1287 - mae: 7.1287\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1231 - mae: 7.1231\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1175 - mae: 7.1175\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1119 - mae: 7.1119\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1062 - mae: 7.1062\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1006 - mae: 7.1006\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.0950 - mae: 7.0950\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0894 - mae: 7.0894\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0781 - mae: 7.0781\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0725 - mae: 7.0725\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0669 - mae: 7.0669\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.0613 - mae: 7.0613\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0556 - mae: 7.0556\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0500 - mae: 7.0500\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0444 - mae: 7.0444\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0388 - mae: 7.0388\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0331 - mae: 7.0331\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0275 - mae: 7.0275\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0219 - mae: 7.0219\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0163 - mae: 7.0163\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.0106 - mae: 7.0106\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0050 - mae: 7.0050\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9994 - mae: 6.9994\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.9938 - mae: 6.9938\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 6.9881 - mae: 6.9881\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9825 - mae: 6.9825\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9769 - mae: 6.9769\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9713 - mae: 6.9713\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9656 - mae: 6.9656\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9600 - mae: 6.9600\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9544 - mae: 6.9544\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9488 - mae: 6.9488\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9431 - mae: 6.9431\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9375 - mae: 6.9375\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9319 - mae: 6.9319\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9263 - mae: 6.9263\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9206 - mae: 6.9206\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.9150 - mae: 6.9150\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.9094 - mae: 6.9094\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9038 - mae: 6.9038\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8981 - mae: 6.8981\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8869 - mae: 6.8869\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4984c69890>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder of the date\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AIrWv-_eWe4",
        "outputId": "b1b4e031-34c5-4b19-9ee6-fef72b4ca10f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See if the model's prediction has improved\n",
        "model.predict([17.0])       # we need it to be 17.0 + 10 = 27.0 for 100% accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6xqTFkQjl3g",
        "outputId": "b8905b57-14f3-4e84-dba8-af1c600145e1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[29.739855]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See if another change can be made to improve the model\n",
        "\n",
        "# 1. Create the model (this time with an extra hidden layer with 100 hidden units)\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation=\"relu\"),    # the change; added an extra hidden layer\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuPxLFYxjsYO",
        "outputId": "d5fc7d9d-b72e-4f26-afde-30a00129e788"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 365ms/step - loss: 12.3193 - mae: 12.3193\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 11.7804 - mae: 11.7804\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2324 - mae: 11.2324\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6601 - mae: 10.6601\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.0632 - mae: 10.0632\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4503 - mae: 9.4503\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.7991 - mae: 8.7991\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.1072 - mae: 8.1072\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.3691 - mae: 7.3691\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5758 - mae: 6.5758\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7205 - mae: 5.7205\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7947 - mae: 4.7947\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3581 - mae: 4.3581\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3134 - mae: 4.3134\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2550 - mae: 4.2550\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2442 - mae: 4.2442\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1520 - mae: 4.1520\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1739 - mae: 4.1739\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0681 - mae: 4.0681\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0807 - mae: 4.0807\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9954 - mae: 3.9954\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9739 - mae: 3.9739\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9208 - mae: 3.9208\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9047 - mae: 3.9047\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.9267 - mae: 3.9267\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8797 - mae: 3.8797\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9341 - mae: 3.9341\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8678 - mae: 3.8678\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9274 - mae: 3.9274\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8751 - mae: 3.8751\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9080 - mae: 3.9080\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8893 - mae: 3.8893\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8834 - mae: 3.8834\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8969 - mae: 3.8969\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8581 - mae: 3.8581\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9046 - mae: 3.9046\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8386 - mae: 3.8386\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9054 - mae: 3.9054\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8482 - mae: 3.8482\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8862 - mae: 3.8862\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8605 - mae: 3.8605\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8608 - mae: 3.8608\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8683 - mae: 3.8683\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8762 - mae: 3.8762\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8106 - mae: 3.8106\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8821 - mae: 3.8821\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8234 - mae: 3.8234\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8626 - mae: 3.8626\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8328 - mae: 3.8328\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8369 - mae: 3.8369\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8408 - mae: 3.8408\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8111 - mae: 3.8111\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8489 - mae: 3.8489\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7850 - mae: 3.7850\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8585 - mae: 3.8585\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7982 - mae: 3.7982\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8377 - mae: 3.8377\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8062 - mae: 3.8062\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8117 - mae: 3.8117\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8144 - mae: 3.8144\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7856 - mae: 3.7856\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8227 - mae: 3.8227\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7593 - mae: 3.7593\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8352 - mae: 3.8352\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7725 - mae: 3.7725\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8115 - mae: 3.8115\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7807 - mae: 3.7807\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7853 - mae: 3.7853\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7891 - mae: 3.7891\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7588 - mae: 3.7588\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7975 - mae: 3.7975\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7337 - mae: 3.7337\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.8105 - mae: 3.8105\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7478 - mae: 3.7478\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7840 - mae: 3.7840\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7563 - mae: 3.7563\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7575 - mae: 3.7575\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7648 - mae: 3.7648\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7307 - mae: 3.7307\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7735 - mae: 3.7735\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7125 - mae: 3.7125\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7820 - mae: 3.7820\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7242 - mae: 3.7242\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7552 - mae: 3.7552\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7329 - mae: 3.7329\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7284 - mae: 3.7284\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7416 - mae: 3.7416\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7013 - mae: 3.7013\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7505 - mae: 3.7505\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6921 - mae: 3.6921\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7522 - mae: 3.7522\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7016 - mae: 3.7016\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.7251 - mae: 3.7251\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7105 - mae: 3.7105\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6979 - mae: 3.6979\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7194 - mae: 3.7194\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6705 - mae: 3.6705\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7299 - mae: 3.7299\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6711 - mae: 3.6711\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f498630d990>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reminder of the data\n",
        "X, y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OadYNGMmhXc",
        "outputId": "cf84c43e-e4a9-4629-a195-65ef887ae9cf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=float64, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.])>,\n",
              " <tf.Tensor: shape=(8,), dtype=float64, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.])>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction\n",
        "model.predict([17.0])         # should be 17.0 + 10 = 27"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmtPzVWBm9eC",
        "outputId": "0def597f-ded7-4fdf-9e3b-5331db686e62"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[31.223137]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model is overfitting! Training is better, but low predictive performance"
      ],
      "metadata": {
        "id": "lWNDF2vWnrOu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See if another change can be made to improve the model\n",
        "\n",
        "# 1. Create the model (this time with an extra hidden layer with 100 hidden units and using optimizer Adam and higher learning rate)\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(100, activation=\"relu\"),    # the first change; added an extra hidden layer\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(lr=0.01),    # the second and third changee; using Adam instead of SGD with higher learning rate by magnitude of 10\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model.fit(tf.expand_dims(X, axis=-1), y, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFLl1WmYnu3t",
        "outputId": "4d99b5aa-4ee0-42bb-f4d3-27baf54a18e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 416ms/step - loss: 12.7339 - mae: 12.7339\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.9052 - mae: 11.9052\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 11.0712 - mae: 11.0712\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.2556 - mae: 10.2556\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.6071 - mae: 9.6071\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9779 - mae: 8.9779\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.3324 - mae: 8.3324\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.6675 - mae: 7.6675\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9773 - mae: 6.9773\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.2578 - mae: 6.2578\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5048 - mae: 5.5048\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 4.7182 - mae: 4.7182\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9977 - mae: 3.9977\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7582 - mae: 3.7582\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8989 - mae: 3.8989\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0165 - mae: 4.0165\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2808 - mae: 4.2808\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4803 - mae: 4.4803\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5805 - mae: 4.5805\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5931 - mae: 4.5931\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5326 - mae: 4.5326\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4073 - mae: 4.4073\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2272 - mae: 4.2272\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0037 - mae: 4.0037\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7757 - mae: 3.7757\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.6633 - mae: 3.6633\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5512 - mae: 3.5512\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4389 - mae: 3.4389\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3275 - mae: 3.3275\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3583 - mae: 3.3583\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3569 - mae: 3.3569\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3252 - mae: 3.3252\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2848 - mae: 3.2848\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2317 - mae: 3.2317\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1251 - mae: 3.1251\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0259 - mae: 3.0259\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9742 - mae: 2.9742\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9566 - mae: 2.9566\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9194 - mae: 2.9194\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8601 - mae: 2.8601\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7829 - mae: 2.7829\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6897 - mae: 2.6897\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5785 - mae: 2.5785\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4573 - mae: 2.4573\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3350 - mae: 2.3350\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2170 - mae: 2.2170\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1181 - mae: 2.1181\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0317 - mae: 2.0317\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9329 - mae: 1.9329\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8220 - mae: 1.8220\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6936 - mae: 1.6936\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5465 - mae: 1.5465\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4338 - mae: 1.4338\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2796 - mae: 1.2796\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1364 - mae: 1.1364\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.0045 - mae: 1.0045\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8414 - mae: 0.8414\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.6584 - mae: 0.6584\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.4793 - mae: 0.4793\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3216 - mae: 0.3216\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2821 - mae: 0.2821\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2139 - mae: 0.2139\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.3067 - mae: 0.3067\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.4669 - mae: 0.4669\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5318 - mae: 0.5318\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.4286 - mae: 0.4286\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6082 - mae: 0.6082\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4514 - mae: 0.4514\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5475 - mae: 0.5475\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4334 - mae: 0.4334\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3996 - mae: 0.3996\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4192 - mae: 0.4192\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4045 - mae: 0.4045\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4016 - mae: 0.4016\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.2396 - mae: 0.2396\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3249 - mae: 0.3249\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.3173 - mae: 0.3173\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2367 - mae: 0.2367\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2889 - mae: 0.2889\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2590 - mae: 0.2590\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.2732 - mae: 0.2732\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.3136 - mae: 0.3136\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2944 - mae: 0.2944\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.2543 - mae: 0.2543\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.2342 - mae: 0.2342\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1792 - mae: 0.1792\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.1477 - mae: 0.1477\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1554 - mae: 0.1554\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.1632 - mae: 0.1632\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1497 - mae: 0.1497\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2270 - mae: 0.2270\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1988 - mae: 0.1988\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2866 - mae: 0.2866\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.2691 - mae: 0.2691\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3802 - mae: 0.3802\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.3505 - mae: 0.3505\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1934 - mae: 0.1934\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4458 - mae: 0.4458\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.4780 - mae: 0.4780\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.2037 - mae: 0.2037\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f498552e250>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try to make a prediction\n",
        "model.predict([17.0])         # should be 17.0 + 10 = 27"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5AgJN5HKn_dL",
        "outputId": "f4c919fc-e958-4a63-ad2d-a2dda4c7d80b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26.43606]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Sidenote:** The learning parameter `lr` is the most important hyperparameter of Neural Networks."
      ],
      "metadata": {
        "id": "fWKV6dQIoI_7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating a Model\n",
        "\n",
        "In practice, a typical workflow one will go through when  building neural networks is:\n",
        "\n",
        "```\n",
        "Build a model -> Fit it -> Evaluate It -> Tweak the Model -> Fit It -> Evaluate It-> Tweak the Model -> Fit It -> Evaluate It...\n",
        "```"
      ],
      "metadata": {
        "id": "6heWRA78G-iD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When it comes to evaluation...3 works to memorize:\n",
        "\n",
        ">\"Visualize, visualize, visualize\"\n",
        "\n",
        "\n",
        "It is a good idea to visualize:\n",
        "* The data -> what is the data? what does it look like?\n",
        "* The model -> what does the model look like?\n",
        "* The training of a model -> how does the model perform while it learns?\n",
        "* The predictions of the model -> how do the predictions of the model line up against the ground truth (the original labels)"
      ],
      "metadata": {
        "id": "A14DvacoHBoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a bigger dataset\n",
        "X = tf.range(-100, 100, 4)   # dtype will be integers and not floats\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzJF8tB_I1YK",
        "outputId": "799d3084-a8d9-430d-c417-76f72fd6ab68"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
              "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
              "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
              "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
              "         76,   80,   84,   88,   92,   96], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make labels for the dataset\n",
        "y = X + 10\n",
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lSTt87lI5CZ",
        "outputId": "4750a6d3-bab6-471a-98e9-f85196cbb467"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
              "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
              "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
              "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
              "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the data\n",
        "import matplotlib.pyplot as ply\n",
        "\n",
        "plt.scatter(X, y);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ToWFCRagJQOx",
        "outputId": "7bd0f71c-3a80-4c9c-8496-56ef051cfc60"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The 3 sets...\n",
        "\n",
        "* **Training Set** - the model learns from this data, which is typically 70-80% of the total data available. (i.e. course materials)\n",
        "* **Validation Set** - the model gets tuned on this data, which is typically 10-15% of the data available. (i.e. practice exam)\n",
        "* **Test Set** - the model gets evaluated on this data to test what it has learned, this set  is typically 10-15% of the total data available. (i.e. final exam)"
      ],
      "metadata": {
        "id": "YgHKDrAVJYjx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the length (how many samples) in the data set\n",
        "len(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG2U0Y4YJqp9",
        "outputId": "4be0c4a8-0875-42f6-a43b-f615cdbcb248"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and test sets\n",
        "X_train = X[:40]   # first 40 are training samples (80% of the data)\n",
        "y_train = y[:40]   \n",
        "\n",
        "X_test = X[40:]     # the last 10 are testing sample (20% of the data)\n",
        "y_test = y[40:]\n",
        "\n",
        "len(X_train), len(X_test), len(y_train), len(y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LggyXjQm7lB",
        "outputId": "6a2f9787-dfc6-4d7d-fe91-dbe1a7dc5834"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40, 10, 40, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the data\n",
        "\n",
        "Now that the data is in training and test data sets...time to visualize it again!"
      ],
      "metadata": {
        "id": "TAW-MCa6nru9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "\n",
        "# Plot training data in blue\n",
        "plt.scatter(X_train, y_train, c=\"b\", label = \"Training Data\")\n",
        "\n",
        "# Plot test data in green\n",
        "plt.scatter(X_test, y_test, c=\"g\", label = \"Testing Data\")\n",
        "\n",
        "# Show a legend\n",
        "plt.legend();"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "Szmg76lMoa7p",
        "outputId": "b2194dfb-a9c8-47a3-b275-7e0f53b5fcc8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How to build a Neural Network for this data\n",
        "\n",
        "# 1. Create a model\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "# model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100)"
      ],
      "metadata": {
        "id": "1Z7XOub5o1e3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the Model"
      ],
      "metadata": {
        "id": "oTrOo5ySsTKb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create  a model which builds automatically by defining the input_shape argument in the first layer\n",
        "tf.random.set_seed(42)    # to allow for reproducibility\n",
        "\n",
        "# 1. Create a model (same as above)\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(10, input_shape=[1], name=\"input_layer\") ,\n",
        "        tf.keras.layers.Dense(1, name=\"output_layer\")    # input shape = 1 because only passing one number in \n",
        "], name = \"model_1\")\n",
        "\n",
        "# 2. Compile the model (same as above)\n",
        "model.compile(loss=tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.SGD(),\n",
        "              metrics = [\"mae\"])"
      ],
      "metadata": {
        "id": "fPC2_vEcvNaW"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()        # shows the number of layers a model contains and the output shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3ePeZgYwPnA",
        "outputId": "5ee25e01-b076-499c-8187-88dafc14e66d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Total Params** - total number of parameters in the model; number of patterns to be learned between the variables\n",
        "* **Trainable Params** - these are the parameters (patterns) the model can update as it trains.\n",
        "* **Non-trainable Params** - these are the parameters that are not updated during training (typical when already learned patters or parameter are brought in from other models during **transfer learning**).\n",
        "\n",
        " **Resource:** For a more in-depth overview of the trainable parameters within a layer, check out MIT's Introduction to Deep Learning video (https://www.youtube.com/watch?v=5tvmMX8r_OM).\n",
        "\n",
        " **Exercise:** Try playing around with the number of idden units in the dense layer, see how that effects the number of parameters (total and trainable) by calling `model.summary()`."
      ],
      "metadata": {
        "id": "lux3lSA7wauA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model to the training data\n",
        "model.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=100, verbose=0)   # verbose=0 will not show the model running"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AQIsB-dxL1X",
        "outputId": "be38462d-68b2-4a0f-a02b-523277f84077"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f498625e0d0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get a summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wbVbHV20M7q",
        "outputId": "e5ff224a-6666-4ee1-bd78-e4661c7bff1c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_layer (Dense)         (None, 10)                20        \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "plot_model(model = model, show_shapes=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "1Ft7URtW0P6o",
        "outputId": "8dbcf6a3-6ef7-438e-d3b6-be37950d8909"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualizing the Model's Predictions\n",
        "\n",
        "To visualize predictions, it is a good idea to plot them against truth labels.\n",
        "\n",
        "Often this is seen in the form of `y_test` or `y_true` vs `y_pred` (ground truth value vs the model's predictions)."
      ],
      "metadata": {
        "id": "9m6z46c80rt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y7IY54G2C71",
        "outputId": "3ca05fdc-e15e-4e4f-9323-17c290932681"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f49861c3320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hLSMfsj3ipf",
        "outputId": "447f114f-bfbc-4572-e238-6e0bab2386cc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Note:** If it feels like you are going to reuse some kind of functionality in the future, it is a good idea to turn it into a function."
      ],
      "metadata": {
        "id": "b5CfJ-_z3zUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create a plotting function\n",
        "def plot_predictions(train_data = X_train,\n",
        "                      train_labels = y_train,\n",
        "                      test_data = X_test,\n",
        "                      test_labels = y_test,\n",
        "                      predictions = y_pred):\n",
        "   \"\"\"\n",
        "   Plot training data, test data and compares predictions to ground truth labels\n",
        "   \"\"\"\n",
        "   plt.figure(figsize=(10, 7))\n",
        "\n",
        "   # Plot training data in blue\n",
        "   plt.scatter(train_data, train_labels, c=\"b\", label=\"Training Data\")\n",
        "   # Plot testing data in green\n",
        "   plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing Data\")\n",
        "   # Plot model's predictions in red\n",
        "   plt.scatter(test_data, predictions, c=\"r\", label = \"Predictions\")\n",
        "   # Show legen\n",
        "   plt.legend();"
      ],
      "metadata": {
        "id": "_NlctP4T3jyu"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions(train_data = X_train,\n",
        "                 train_labels = y_train,\n",
        "                 test_data = X_test,\n",
        "                 test_labels = y_test,\n",
        "                 predictions = y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "F3DmnX0T9SUs",
        "outputId": "3b6650a4-105e-43c2-e29a-608c1c2afd20"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the Model's Predictions with Regression Evaluation Metrics\n",
        "\n",
        "Depending on the problem being solved, there will be different evaluation metrics to evaluate the model's performance.\n",
        "\n",
        "Since this is a regression model, two of the main metrics:\n",
        "* **MAE** - Mean Absolute Error, \"on average, how wrong is each of the model's predictions\"; use for any regression problem\n",
        ">  `tf.keras.losses.MAE()` or `tf.metrics.mean_absolute_error()`\n",
        "\n",
        "* **MSE** - Mean Square Error, \"square the average errors\"; use when larger errors are more significant than smaller errors.\n",
        "> `tf.keras.losses.MSE()` or ` tf.metrics.mean_square_error()`\n",
        "\n",
        "* **Huber** - combination of MSE and MAE; less sensitive to outliers than MSE\n",
        "> `tf.keras.losses.Huber()`"
      ],
      "metadata": {
        "id": "Py4MkucZ9cIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4LQHfH799pV",
        "outputId": "a59e0253-e3dc-44d5-9c77-0e40e07ce22b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 159ms/step - loss: 3.1969 - mae: 3.1969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.196942090988159, 3.196942090988159]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = tf.metrics.mean_absolute_error(y_true = y_test, \n",
        "                                     y_pred = tf.constant(y_pred))\n",
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gfelrCHAWZd",
        "outputId": "ac45958f-ffcf-49c8-b9ee-2b7079538f71"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([17.558258 , 14.1160555, 11.708948 , 10.336929 , 10.       ,\n",
              "       10.698161 , 12.447118 , 15.333002 , 19.253975 , 23.841698 ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The outputs are different because the shapes are different (10,) and (10,1)"
      ],
      "metadata": {
        "id": "-TjwvCeHBZzT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(y_pred) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIAYJWLQA7K9",
        "outputId": "9b854cde-585c-4745-d7cf-9c124cee4e2a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
              "array([[ 70.55218 ],\n",
              "       [ 75.13991 ],\n",
              "       [ 79.72763 ],\n",
              "       [ 84.31535 ],\n",
              "       [ 88.903076],\n",
              "       [ 93.49081 ],\n",
              "       [ 98.07853 ],\n",
              "       [102.66625 ],\n",
              "       [107.253975],\n",
              "       [111.8417  ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saLaYn73AVFQ",
        "outputId": "cfe48b32-23c2-4e4f-d60a-81a0faa13f08"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.squeeze(y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17Khc-wXAVrp",
        "outputId": "5ce76f05-4dab-4650-d229-885b1b131a54"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
              "array([ 70.55218 ,  75.13991 ,  79.72763 ,  84.31535 ,  88.903076,\n",
              "        93.49081 ,  98.07853 , 102.66625 , 107.253975, 111.8417  ],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean absolute error (MAE)\n",
        "mae = tf.metrics.mean_absolute_error(y_true = y_test,\n",
        "                                     y_pred = tf.squeeze(y_pred))\n",
        "mae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI9WWhlxBTQB",
        "outputId": "21bc9713-54cd-4636-9ee5-85e1aff56786"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=3.1969407>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now the output matches the evaluation of the model from `model.evaluate()`"
      ],
      "metadata": {
        "id": "05Kce7zNBtFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean square error (MSE)\n",
        "mse = tf.metrics.mean_squared_error(y_true = y_test,\n",
        "                                    y_pred = tf.squeeze(y_pred))\n",
        "mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHTLbnmbB5jS",
        "outputId": "c3492895-5f28-4da0-ca8f-2bc28bf39e0f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=13.070143>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MSE > MAE, typically"
      ],
      "metadata": {
        "id": "u0zfQlqgCGkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make some functions to reuse MAE and MSE\n",
        "def mae(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Returns the Mean Absolute Error given \n",
        "  the test data set and predictions\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_absolute_error(y_true = y_true,\n",
        "                                        y_pred = tf.squeeze(y_pred)).numpy()\n",
        "  \n",
        "def mse(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Returns the Mean Squared Error given \n",
        "  the inputs of the test data set and predictions.\n",
        "  \"\"\"\n",
        "  return tf.metrics.mean_squared_error(y_true = y_true,\n",
        "                                       y_pred = tf.squeeze(y_pred)).numpy()\n",
        "\n",
        "# \".numpy()\" --> allow for just the value to output rather than the tf.tensor blah blah blah"
      ],
      "metadata": {
        "id": "Ex3dkbx3CWNO"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running  Experiments to Improve the Model\n",
        "\n",
        "```\n",
        "Build a Model -> Fit It -> Evaluate It -> Tweak It -> Fit It -> Evaluate It...\n",
        "```\n",
        "\n",
        "1. Get more data - get more examples for the model to train on (more opportunities to learn patterns or relationships between features and labels).\n",
        "2. Make the model larger (using a more complex model) - this might come in the form of more layers or more hidden units in each layer.\n",
        "3. Train for longer - give the model more of a chance to find patterns in the data.\n",
        "\n",
        "\n",
        "Let's do 3 modelling experiments:\n",
        "1. `model_1` - same as the original model, 1 layer, trained for 100 epochs.\n",
        "2. `model_2` - 2 layers, trained for 100 epochs\n",
        "3. `model_3` - 2 layers, trained for 500 epochs\n",
        "\n",
        "**Build `model_1`**"
      ],
      "metadata": {
        "id": "GGfUxooGCu6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)    # for reproducibility\n",
        "\n",
        "# 1. Create the model\n",
        "model_1 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_1.compile(loss = tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.SGD(),\n",
        "                metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_1.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqsMSYQ_C6rc",
        "outputId": "ecaa7d66-841d-449e-8363-99bd6224c9ff"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.9024 - mae: 15.9024\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.2837 - mae: 11.2837\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.1074 - mae: 11.1074\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.2991 - mae: 9.2991\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1677 - mae: 10.1677\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4303 - mae: 9.4303\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.5704 - mae: 8.5704\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0442 - mae: 9.0442\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.7517 - mae: 18.7517\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1142 - mae: 10.1142\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.3980 - mae: 8.3980\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6639 - mae: 10.6639\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7977 - mae: 9.7977\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.0103 - mae: 16.0103\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4068 - mae: 11.4068\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 24ms/step - loss: 8.5393 - mae: 8.5393\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 13.6348 - mae: 13.6348\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 11.4629 - mae: 11.4629\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.9148 - mae: 17.9148\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 15.0494 - mae: 15.0494\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 11.0216 - mae: 11.0216\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.1558 - mae: 8.1558\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5138 - mae: 9.5138\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6617 - mae: 7.6617\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.1859 - mae: 13.1859\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.4211 - mae: 16.4211\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.1660 - mae: 13.1660\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 14.2559 - mae: 14.2559\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0670 - mae: 10.0670\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3409 - mae: 16.3409\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.6444 - mae: 23.6444\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6215 - mae: 7.6215\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3221 - mae: 9.3221\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7313 - mae: 13.7313\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1276 - mae: 11.1276\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.3222 - mae: 13.3222\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.4763 - mae: 9.4763\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.1381 - mae: 10.1381\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.1793 - mae: 10.1793\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9137 - mae: 10.9137\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.9063 - mae: 7.9063\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.0914 - mae: 10.0914\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7006 - mae: 8.7006\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.2047 - mae: 12.2047\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7970 - mae: 13.7970\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.4687 - mae: 8.4687\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1330 - mae: 9.1330\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6190 - mae: 10.6190\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.7503 - mae: 7.7503\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.5407 - mae: 9.5407\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.1584 - mae: 9.1584\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.3630 - mae: 16.3630\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.1299 - mae: 14.1299\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 21.1247 - mae: 21.1247\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.3961 - mae: 16.3961\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.9806 - mae: 9.9806\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.9606 - mae: 9.9606\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2209 - mae: 9.2209\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.4239 - mae: 8.4239\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4869 - mae: 9.4869\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4355 - mae: 11.4355\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.6887 - mae: 11.6887\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.0838 - mae: 7.0838\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.9675 - mae: 16.9675\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4599 - mae: 12.4599\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.0184 - mae: 13.0184\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.0600 - mae: 8.0600\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.1888 - mae: 10.1888\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.3633 - mae: 12.3633\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0516 - mae: 9.0516\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.0378 - mae: 10.0378\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0516 - mae: 10.0516\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6151 - mae: 12.6151\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3819 - mae: 10.3819\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7229 - mae: 9.7229\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.2252 - mae: 11.2252\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.3642 - mae: 8.3642\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.1274 - mae: 9.1274\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5039 - mae: 19.5039\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.8945 - mae: 14.8945\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0034 - mae: 9.0034\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0206 - mae: 13.0206\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.9299 - mae: 7.9299\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.6872 - mae: 7.6872\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.0328 - mae: 10.0328\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2433 - mae: 9.2433\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.0209 - mae: 12.0209\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.6389 - mae: 10.6389\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 7.2667 - mae: 7.2667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7786 - mae: 12.7786\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.3481 - mae: 7.3481\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.7175 - mae: 7.7175\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1263 - mae: 7.1263\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.6190 - mae: 12.6190\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.0912 - mae: 10.0912\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3558 - mae: 9.3558\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6834 - mae: 12.6834\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.6762 - mae: 8.6762\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.4693 - mae: 9.4693\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7067 - mae: 8.7067\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4986474a90>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions for model_1\n",
        "y_preds_1 = model_1.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "3fiIppNbDkAv",
        "outputId": "8cb3570d-c89e-4b4c-c304-21cf06e16a2e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f498b016dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNESIdoTHn3x",
        "outputId": "1b46d063-9030-4cad-ec38-29e9047e35d5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_1 evaluation metrics\n",
        "mae_1 = mae(y_test, y_preds_1)\n",
        "mse_1 = mse(y_test, y_preds_1)\n",
        "\n",
        "mae_1, mse_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJwxbQGUGZNv",
        "outputId": "6d716d5e-d467-46f4-f452-30fc27990acb"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18.745327, 353.57336)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build `model_2`\n",
        "\n",
        "* 2 dense layers, trained for 100 epochs"
      ],
      "metadata": {
        "id": "I0S31dtLGnId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the random seed\n",
        "tf.random.set_seed(42)    # for reproducibility\n",
        "\n",
        "# 1. Create the model (2 dense layers)\n",
        "model_2 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(10),           # arbitrary number of 10 hidden units           \n",
        "          tf.keras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_2.compile(loss=tf.keras.losses.mae,\n",
        "                optimizer=tf.keras.optimizers.SGD(),\n",
        "                metrics = [\"mse\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_2.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs = 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t94ZN8WRdGeO",
        "outputId": "d3ed62de-a60e-465b-fd87-8a332a339153"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.4058 - mse: 1084.1482\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 24.6339 - mse: 777.9203\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.8935 - mse: 1334.8956\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 27.4055 - mse: 1106.8035\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.9463 - mse: 281.1077\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.8819 - mse: 168.6621\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1988 - mse: 151.3509\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0910 - mse: 160.3745\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.4763 - mse: 2586.0090\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.8688 - mse: 1094.4382\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2473 - mse: 147.9359\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 25.2803 - mse: 890.3866\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.9897 - mse: 399.9678\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.9217 - mse: 1049.5515\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9948 - mse: 450.2580\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.3510 - mse: 80.6206\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8636 - mse: 174.7868\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.5304 - mse: 565.8053\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.3469 - mse: 167.7749\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.6985 - mse: 455.7096\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8984 - mse: 347.1929\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.1991 - mse: 285.1767\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7720 - mse: 91.7852\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0570 - mse: 153.7430\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.6838 - mse: 233.2949\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 26.1877 - mse: 1024.6091\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7432 - mse: 194.8454\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.8730 - mse: 835.6074\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2459 - mse: 96.7786\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.2641 - mse: 1535.1349\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 53.0225 - mse: 5030.2988\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.9951 - mse: 211.7025\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6357 - mse: 337.3666\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.6925 - mse: 214.4824\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mse: 92.9126\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6497 - mse: 403.6573\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0382 - mse: 192.3919\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.1634 - mse: 433.6717\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1013 - mse: 529.6439\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.4324 - mse: 610.1324\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9102 - mse: 279.6183\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2809 - mse: 186.6180\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mse: 167.0952\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mse: 830.4244\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.3897 - mse: 128.9549\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.7904 - mse: 181.9212\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mse: 153.8708\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.2335 - mse: 402.8494\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5729 - mse: 99.8337\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.8185 - mse: 260.3670\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.5958 - mse: 154.7956\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.5538 - mse: 1613.0886\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mse: 302.5293\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.9713 - mse: 859.3983\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.1938 - mse: 805.5452\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.8837 - mse: 170.9834\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.7445 - mse: 198.7015\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5995 - mse: 102.5890\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.5172 - mse: 216.3367\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mse: 208.6371\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4604 - mse: 428.6393\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6052 - mse: 136.9777\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4893 - mse: 152.4555\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.8450 - mse: 911.7512\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6761 - mse: 142.7374\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.7809 - mse: 704.4492\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7136 - mse: 136.0194\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6397 - mse: 149.2300\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 22.6914 - mse: 742.1761\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.3316 - mse: 166.1628\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.4355 - mse: 323.0843\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.7437 - mse: 67.0210\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.6891 - mse: 183.7296\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.0400 - mse: 908.8992\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.5896 - mse: 149.3948\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4371 - mse: 188.3310\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6489 - mse: 429.2708\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.0614 - mse: 95.4870\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 16ms/step - loss: 23.9675 - mse: 864.0864\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.7463 - mse: 1104.4032\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6714 - mse: 170.7055\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.0228 - mse: 211.9191\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4218 - mse: 395.5589\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.2629 - mse: 73.0935\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.9650 - mse: 312.8361\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.2862 - mse: 315.3605\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.1086 - mse: 521.2534\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 29.8229 - mse: 1287.1907\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.1742 - mse: 124.1342\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 21.5240 - mse: 663.8611\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.5716 - mse: 161.7467\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.3977 - mse: 464.1326\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.4138 - mse: 81.9820\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.7380 - mse: 445.7379\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.1144 - mse: 164.0820\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.4346 - mse: 510.5842\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.1593 - mse: 209.9755\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5653 - mse: 169.4052\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.8827 - mse: 265.4630\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.2277 - mse: 608.8218\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4983196290>"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot predictions of model_2\n",
        "y_preds_2 = model_2.predict(X_test)\n",
        "plot_predictions(predictions=y_preds_2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "gyLEYUHBjPWo",
        "outputId": "ffe38c73-2ac1-4d48-b5e1-22b065693550"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate model_2 evaluation metrics\n",
        "mae_2 = mae(y_test, y_preds_2)\n",
        "mse_2 = mse(y_test, y_preds_2)\n",
        "\n",
        "mae_2, mse_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTbUwYwRj04f",
        "outputId": "1e2b3766-bc69-4899-8ade-cd3fe2689925"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3.1969407, 13.070143)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build `model_3`**\n",
        "\n",
        "* 2 layers, trained for 500 epochs"
      ],
      "metadata": {
        "id": "VqWEjYsUkxw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)   # to allow reproducibility\n",
        "\n",
        "# 1. Create the model\n",
        "model_3 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Dense(10),            # a layer with 10 hidden units  \n",
        "          tf.keras.layers.Dense(1)                   \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model_3.compile(loss = tf.keras.losses.mae,\n",
        "                optimizer = tf.keras.optimizers.SGD(),\n",
        "                metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "model_3.fit(tf.expand_dims(X_train, axis=-1), y_train, epochs=500)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaSV_P4nleu_",
        "outputId": "eb5aea89-4589-48a0-b965-b1cf839ce644"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.4058 - mae: 27.4058\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.6339 - mae: 24.6339\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 29.8935 - mae: 29.8935\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 27.4055 - mae: 27.4055\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.9463 - mae: 14.9463\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.8819 - mae: 11.8819\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 11.1988 - mae: 11.1988\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.0910 - mae: 11.0910\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 40.4763 - mae: 40.4763\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.8688 - mae: 27.8688\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.2473 - mae: 10.2473\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.2803 - mae: 25.2803\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9897 - mae: 16.9897\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 25.9217 - mae: 25.9217\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.9948 - mae: 17.9948\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.3510 - mae: 7.3510\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.8636 - mae: 10.8636\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 19.5304 - mae: 19.5304\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.3469 - mae: 10.3469\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.6985 - mae: 17.6985\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.8984 - mae: 15.8984\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.1991 - mae: 14.1991\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.7720 - mae: 8.7720\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0570 - mae: 11.0570\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.1877 - mae: 26.1877\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.7432 - mae: 11.7432\n",
            "Epoch 28/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.8730 - mae: 22.8730\n",
            "Epoch 29/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2459 - mae: 9.2459\n",
            "Epoch 30/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 29.2641 - mae: 29.2641\n",
            "Epoch 31/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 53.0225 - mae: 53.0225\n",
            "Epoch 32/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.9951 - mae: 11.9951\n",
            "Epoch 33/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.6357 - mae: 15.6357\n",
            "Epoch 34/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.6925 - mae: 12.6925\n",
            "Epoch 35/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mae: 9.2398\n",
            "Epoch 36/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.6497 - mae: 16.6497\n",
            "Epoch 37/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0382 - mae: 11.0382\n",
            "Epoch 38/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mae: 18.1634\n",
            "Epoch 39/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1013 - mae: 19.1013\n",
            "Epoch 40/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.4324 - mae: 20.4324\n",
            "Epoch 41/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9102 - mae: 14.9102\n",
            "Epoch 42/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.2809 - mae: 12.2809\n",
            "Epoch 43/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mae: 10.7333\n",
            "Epoch 44/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.0260 - mae: 23.0260\n",
            "Epoch 45/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.3897 - mae: 10.3897\n",
            "Epoch 46/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.7904 - mae: 11.7904\n",
            "Epoch 47/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mae: 9.6438\n",
            "Epoch 48/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.2335 - mae: 17.2335\n",
            "Epoch 49/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5729 - mae: 9.5729\n",
            "Epoch 50/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.8185 - mae: 13.8185\n",
            "Epoch 51/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mae: 11.5958\n",
            "Epoch 52/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 30.5538 - mae: 30.5538\n",
            "Epoch 53/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.3541 - mae: 14.3541\n",
            "Epoch 54/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.9713 - mae: 23.9713\n",
            "Epoch 55/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.1938 - mae: 23.1938\n",
            "Epoch 56/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.8837 - mae: 10.8837\n",
            "Epoch 57/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.7445 - mae: 12.7445\n",
            "Epoch 58/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5995 - mae: 9.5995\n",
            "Epoch 59/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.5172 - mae: 12.5172\n",
            "Epoch 60/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mae: 12.3200\n",
            "Epoch 61/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4604 - mae: 17.4604\n",
            "Epoch 62/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6052 - mae: 10.6052\n",
            "Epoch 63/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.4893 - mae: 10.4893\n",
            "Epoch 64/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.8450 - mae: 24.8450\n",
            "Epoch 65/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.6761 - mae: 10.6761\n",
            "Epoch 66/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.7809 - mae: 21.7809\n",
            "Epoch 67/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.7136 - mae: 10.7136\n",
            "Epoch 68/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6397 - mae: 10.6397\n",
            "Epoch 69/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.6914 - mae: 22.6914\n",
            "Epoch 70/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.3316 - mae: 9.3316\n",
            "Epoch 71/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 15.4355 - mae: 15.4355\n",
            "Epoch 72/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 6.7437 - mae: 6.7437\n",
            "Epoch 73/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mae: 11.6891\n",
            "Epoch 74/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 24.0400 - mae: 24.0400\n",
            "Epoch 75/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5896 - mae: 9.5896\n",
            "Epoch 76/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4371 - mae: 12.4371\n",
            "Epoch 77/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 16.6489 - mae: 16.6489\n",
            "Epoch 78/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0614 - mae: 9.0614\n",
            "Epoch 79/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.9675 - mae: 23.9675\n",
            "Epoch 80/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 26.7463 - mae: 26.7463\n",
            "Epoch 81/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.6714 - mae: 11.6714\n",
            "Epoch 82/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.0228 - mae: 12.0228\n",
            "Epoch 83/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4218 - mae: 17.4218\n",
            "Epoch 84/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.2629 - mae: 7.2629\n",
            "Epoch 85/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9650 - mae: 14.9650\n",
            "Epoch 86/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.2862 - mae: 15.2862\n",
            "Epoch 87/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.1086 - mae: 19.1086\n",
            "Epoch 88/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.8229 - mae: 29.8229\n",
            "Epoch 89/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1742 - mae: 10.1742\n",
            "Epoch 90/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.5240 - mae: 21.5240\n",
            "Epoch 91/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5716 - mae: 10.5716\n",
            "Epoch 92/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3977 - mae: 18.3977\n",
            "Epoch 93/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.4138 - mae: 7.4138\n",
            "Epoch 94/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.7380 - mae: 17.7380\n",
            "Epoch 95/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.1144 - mae: 11.1144\n",
            "Epoch 96/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 19.4346 - mae: 19.4346\n",
            "Epoch 97/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.1593 - mae: 12.1593\n",
            "Epoch 98/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.5653 - mae: 11.5653\n",
            "Epoch 99/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 13.8827 - mae: 13.8827\n",
            "Epoch 100/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 20.2277 - mae: 20.2277\n",
            "Epoch 101/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4479 - mae: 11.4479\n",
            "Epoch 102/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.4842 - mae: 17.4842\n",
            "Epoch 103/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.0217 - mae: 7.0217\n",
            "Epoch 104/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 23.5789 - mae: 23.5789\n",
            "Epoch 105/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 16.8932 - mae: 16.8932\n",
            "Epoch 106/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.2954 - mae: 9.2954\n",
            "Epoch 107/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.3749 - mae: 25.3749\n",
            "Epoch 108/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.4621 - mae: 13.4621\n",
            "Epoch 109/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5238 - mae: 9.5238\n",
            "Epoch 110/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 111/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5987 - mae: 14.5987\n",
            "Epoch 112/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5670 - mae: 9.5670\n",
            "Epoch 113/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.8092 - mae: 17.8092\n",
            "Epoch 114/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.1782 - mae: 17.1782\n",
            "Epoch 115/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.1182 - mae: 11.1182\n",
            "Epoch 116/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.3071 - mae: 23.3071\n",
            "Epoch 117/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.6144 - mae: 9.6144\n",
            "Epoch 118/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.6899 - mae: 10.6899\n",
            "Epoch 119/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0355 - mae: 8.0355\n",
            "Epoch 120/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.6859 - mae: 29.6859\n",
            "Epoch 121/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.0714 - mae: 8.0714\n",
            "Epoch 122/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.3086 - mae: 28.3086\n",
            "Epoch 123/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.9014 - mae: 32.9014\n",
            "Epoch 124/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 19.6291 - mae: 19.6291\n",
            "Epoch 125/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0095 - mae: 7.0095\n",
            "Epoch 126/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.8056 - mae: 21.8056\n",
            "Epoch 127/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.9812 - mae: 7.9812\n",
            "Epoch 128/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.0585 - mae: 21.0585\n",
            "Epoch 129/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.0107 - mae: 9.0107\n",
            "Epoch 130/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 24.0502 - mae: 24.0502\n",
            "Epoch 131/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.7537 - mae: 9.7537\n",
            "Epoch 132/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.3052 - mae: 18.3052\n",
            "Epoch 133/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.5833 - mae: 7.5833\n",
            "Epoch 134/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.5755 - mae: 18.5755\n",
            "Epoch 135/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.5360 - mae: 10.5360\n",
            "Epoch 136/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 18.2694 - mae: 18.2694\n",
            "Epoch 137/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 23.1658 - mae: 23.1658\n",
            "Epoch 138/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.1362 - mae: 9.1362\n",
            "Epoch 139/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.9181 - mae: 8.9181\n",
            "Epoch 140/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4732 - mae: 16.4732\n",
            "Epoch 141/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4208 - mae: 8.4208\n",
            "Epoch 142/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 36.9540 - mae: 36.9540\n",
            "Epoch 143/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.5820 - mae: 25.5820\n",
            "Epoch 144/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.5392 - mae: 9.5392\n",
            "Epoch 145/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 26.6058 - mae: 26.6058\n",
            "Epoch 146/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7248 - mae: 8.7248\n",
            "Epoch 147/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.6172 - mae: 15.6172\n",
            "Epoch 148/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3065 - mae: 18.3065\n",
            "Epoch 149/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.1994 - mae: 8.1994\n",
            "Epoch 150/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.4964 - mae: 7.4964\n",
            "Epoch 151/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3374 - mae: 18.3374\n",
            "Epoch 152/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.2895 - mae: 10.2895\n",
            "Epoch 153/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.6425 - mae: 29.6425\n",
            "Epoch 154/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.5556 - mae: 10.5556\n",
            "Epoch 155/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.4537 - mae: 15.4537\n",
            "Epoch 156/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.0174 - mae: 17.0174\n",
            "Epoch 157/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 32.8218 - mae: 32.8218\n",
            "Epoch 158/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7038 - mae: 10.7038\n",
            "Epoch 159/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.9054 - mae: 8.9054\n",
            "Epoch 160/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 22.1321 - mae: 22.1321\n",
            "Epoch 161/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.7113 - mae: 11.7113\n",
            "Epoch 162/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.5734 - mae: 21.5734\n",
            "Epoch 163/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.2485 - mae: 19.2485\n",
            "Epoch 164/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0156 - mae: 11.0156\n",
            "Epoch 165/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6187 - mae: 9.6187\n",
            "Epoch 166/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.5908 - mae: 21.5908\n",
            "Epoch 167/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.2851 - mae: 26.2851\n",
            "Epoch 168/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8525 - mae: 9.8525\n",
            "Epoch 169/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.5630 - mae: 22.5630\n",
            "Epoch 170/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.1499 - mae: 10.1499\n",
            "Epoch 171/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 18.0464 - mae: 18.0464\n",
            "Epoch 172/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.8377 - mae: 28.8377\n",
            "Epoch 173/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.5279 - mae: 16.5279\n",
            "Epoch 174/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.2115 - mae: 11.2115\n",
            "Epoch 175/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 27.5839 - mae: 27.5839\n",
            "Epoch 176/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2680 - mae: 8.2680\n",
            "Epoch 177/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.2580 - mae: 9.2580\n",
            "Epoch 178/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.1440 - mae: 18.1440\n",
            "Epoch 179/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5995 - mae: 10.5995\n",
            "Epoch 180/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.8992 - mae: 7.8992\n",
            "Epoch 181/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.4015 - mae: 17.4015\n",
            "Epoch 182/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.0089 - mae: 11.0089\n",
            "Epoch 183/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.7027 - mae: 11.7027\n",
            "Epoch 184/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.4062 - mae: 30.4062\n",
            "Epoch 185/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5557 - mae: 7.5557\n",
            "Epoch 186/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 15.9905 - mae: 15.9905\n",
            "Epoch 187/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.5579 - mae: 8.5579\n",
            "Epoch 188/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 28.7339 - mae: 28.7339\n",
            "Epoch 189/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.1689 - mae: 13.1689\n",
            "Epoch 190/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.3101 - mae: 18.3101\n",
            "Epoch 191/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7376 - mae: 13.7376\n",
            "Epoch 192/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.7104 - mae: 13.7104\n",
            "Epoch 193/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 28.5842 - mae: 28.5842\n",
            "Epoch 194/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.0707 - mae: 7.0707\n",
            "Epoch 195/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 7.0550 - mae: 7.0550\n",
            "Epoch 196/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.0067 - mae: 22.0067\n",
            "Epoch 197/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.8443 - mae: 20.8443\n",
            "Epoch 198/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.4713 - mae: 12.4713\n",
            "Epoch 199/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 17.9099 - mae: 17.9099\n",
            "Epoch 200/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 13.7494 - mae: 13.7494\n",
            "Epoch 201/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.4687 - mae: 5.4687\n",
            "Epoch 202/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.7006 - mae: 13.7006\n",
            "Epoch 203/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.4142 - mae: 9.4142\n",
            "Epoch 204/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.9796 - mae: 20.9796\n",
            "Epoch 205/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.5470 - mae: 9.5470\n",
            "Epoch 206/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.7256 - mae: 11.7256\n",
            "Epoch 207/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.3772 - mae: 14.3772\n",
            "Epoch 208/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.8579 - mae: 14.8579\n",
            "Epoch 209/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.9706 - mae: 14.9706\n",
            "Epoch 210/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.8998 - mae: 17.8998\n",
            "Epoch 211/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8327 - mae: 9.8327\n",
            "Epoch 212/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 18.3352 - mae: 18.3352\n",
            "Epoch 213/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0383 - mae: 15.0383\n",
            "Epoch 214/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.5874 - mae: 14.5874\n",
            "Epoch 215/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 23.3015 - mae: 23.3015\n",
            "Epoch 216/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3613 - mae: 13.3613\n",
            "Epoch 217/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.8517 - mae: 9.8517\n",
            "Epoch 218/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.5451 - mae: 12.5451\n",
            "Epoch 219/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 4.9472 - mae: 4.9472\n",
            "Epoch 220/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.1130 - mae: 7.1130\n",
            "Epoch 221/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 35.4567 - mae: 35.4567\n",
            "Epoch 222/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 34.8634 - mae: 34.8634\n",
            "Epoch 223/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 7.9846 - mae: 7.9846\n",
            "Epoch 224/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.7004 - mae: 14.7004\n",
            "Epoch 225/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.7196 - mae: 16.7196\n",
            "Epoch 226/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.9329 - mae: 15.9329\n",
            "Epoch 227/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 16.1644 - mae: 16.1644\n",
            "Epoch 228/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 13.9324 - mae: 13.9324\n",
            "Epoch 229/500\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 18.0504 - mae: 18.0504\n",
            "Epoch 230/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.6120 - mae: 15.6120\n",
            "Epoch 231/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 21.2041 - mae: 21.2041\n",
            "Epoch 232/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.2732 - mae: 25.2732\n",
            "Epoch 233/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.3176 - mae: 16.3176\n",
            "Epoch 234/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.2729 - mae: 7.2729\n",
            "Epoch 235/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.9688 - mae: 16.9688\n",
            "Epoch 236/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 7.1225 - mae: 7.1225\n",
            "Epoch 237/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.2058 - mae: 9.2058\n",
            "Epoch 238/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.0961 - mae: 8.0961\n",
            "Epoch 239/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.0538 - mae: 17.0538\n",
            "Epoch 240/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.8627 - mae: 8.8627\n",
            "Epoch 241/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.1711 - mae: 13.1711\n",
            "Epoch 242/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.7886 - mae: 8.7886\n",
            "Epoch 243/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 18.8161 - mae: 18.8161\n",
            "Epoch 244/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.0531 - mae: 14.0531\n",
            "Epoch 245/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.6831 - mae: 14.6831\n",
            "Epoch 246/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.8045 - mae: 15.8045\n",
            "Epoch 247/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.6810 - mae: 17.6810\n",
            "Epoch 248/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.2367 - mae: 13.2367\n",
            "Epoch 249/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.5070 - mae: 14.5070\n",
            "Epoch 250/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.2322 - mae: 23.2322\n",
            "Epoch 251/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.3009 - mae: 9.3009\n",
            "Epoch 252/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 36.6569 - mae: 36.6569\n",
            "Epoch 253/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.8205 - mae: 21.8205\n",
            "Epoch 254/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.2792 - mae: 7.2792\n",
            "Epoch 255/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.7127 - mae: 24.7127\n",
            "Epoch 256/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 12.4220 - mae: 12.4220\n",
            "Epoch 257/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.5823 - mae: 10.5823\n",
            "Epoch 258/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.4883 - mae: 14.4883\n",
            "Epoch 259/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 8.6132 - mae: 8.6132\n",
            "Epoch 260/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 43.0580 - mae: 43.0580\n",
            "Epoch 261/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 18.4611 - mae: 18.4611\n",
            "Epoch 262/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8820 - mae: 6.8820\n",
            "Epoch 263/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.7211 - mae: 13.7211\n",
            "Epoch 264/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.0154 - mae: 21.0154\n",
            "Epoch 265/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 19.3731 - mae: 19.3731\n",
            "Epoch 266/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.4735 - mae: 11.4735\n",
            "Epoch 267/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5302 - mae: 7.5302\n",
            "Epoch 268/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 21.6453 - mae: 21.6453\n",
            "Epoch 269/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.1785 - mae: 33.1785\n",
            "Epoch 270/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0833 - mae: 10.0833\n",
            "Epoch 271/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.1012 - mae: 12.1012\n",
            "Epoch 272/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 26.1372 - mae: 26.1372\n",
            "Epoch 273/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.1751 - mae: 12.1751\n",
            "Epoch 274/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 13.3272 - mae: 13.3272\n",
            "Epoch 275/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 29.3775 - mae: 29.3775\n",
            "Epoch 276/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.3329 - mae: 7.3329\n",
            "Epoch 277/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.1362 - mae: 31.1362\n",
            "Epoch 278/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.3015 - mae: 12.3015\n",
            "Epoch 279/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.4103 - mae: 16.4103\n",
            "Epoch 280/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 21.9118 - mae: 21.9118\n",
            "Epoch 281/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 22.1501 - mae: 22.1501\n",
            "Epoch 282/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.7429 - mae: 7.7429\n",
            "Epoch 283/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.1429 - mae: 8.1429\n",
            "Epoch 284/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 24.9435 - mae: 24.9435\n",
            "Epoch 285/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.6958 - mae: 13.6958\n",
            "Epoch 286/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 6.8926 - mae: 6.8926\n",
            "Epoch 287/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.5352 - mae: 24.5352\n",
            "Epoch 288/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.1721 - mae: 20.1721\n",
            "Epoch 289/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.9658 - mae: 11.9658\n",
            "Epoch 290/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.5391 - mae: 16.5391\n",
            "Epoch 291/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.8017 - mae: 16.8017\n",
            "Epoch 292/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 293/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 15.2711 - mae: 15.2711\n",
            "Epoch 294/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 22.7179 - mae: 22.7179\n",
            "Epoch 295/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9234 - mae: 17.9234\n",
            "Epoch 296/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.1743 - mae: 6.1743\n",
            "Epoch 297/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 10.9440 - mae: 10.9440\n",
            "Epoch 298/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 23.1530 - mae: 23.1530\n",
            "Epoch 299/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 17.7331 - mae: 17.7331\n",
            "Epoch 300/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 6.9824 - mae: 6.9824\n",
            "Epoch 301/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.1857 - mae: 25.1857\n",
            "Epoch 302/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 8.9025 - mae: 8.9025\n",
            "Epoch 303/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.7668 - mae: 17.7668\n",
            "Epoch 304/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0002 - mae: 11.0002\n",
            "Epoch 305/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.9191 - mae: 12.9191\n",
            "Epoch 306/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.4033 - mae: 8.4033\n",
            "Epoch 307/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.6094 - mae: 13.6094\n",
            "Epoch 308/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.4404 - mae: 7.4404\n",
            "Epoch 309/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.4642 - mae: 9.4642\n",
            "Epoch 310/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.7099 - mae: 10.7099\n",
            "Epoch 311/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.2814 - mae: 13.2814\n",
            "Epoch 312/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 29.9763 - mae: 29.9763\n",
            "Epoch 313/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6304 - mae: 7.6304\n",
            "Epoch 314/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.9106 - mae: 9.9106\n",
            "Epoch 315/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 23.7669 - mae: 23.7669\n",
            "Epoch 316/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.3937 - mae: 16.3937\n",
            "Epoch 317/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.0758 - mae: 21.0758\n",
            "Epoch 318/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 7.9367 - mae: 7.9367\n",
            "Epoch 319/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 17.9731 - mae: 17.9731\n",
            "Epoch 320/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.2375 - mae: 10.2375\n",
            "Epoch 321/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 8.3338 - mae: 8.3338\n",
            "Epoch 322/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.0621 - mae: 5.0621\n",
            "Epoch 323/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.5109 - mae: 23.5109\n",
            "Epoch 324/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 6.8309 - mae: 6.8309\n",
            "Epoch 325/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.3863 - mae: 16.3863\n",
            "Epoch 326/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.5019 - mae: 7.5019\n",
            "Epoch 327/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 20.0573 - mae: 20.0573\n",
            "Epoch 328/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.7661 - mae: 13.7661\n",
            "Epoch 329/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.8282 - mae: 16.8282\n",
            "Epoch 330/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0514 - mae: 7.0514\n",
            "Epoch 331/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.4846 - mae: 21.4846\n",
            "Epoch 332/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.2880 - mae: 12.2880\n",
            "Epoch 333/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.8117 - mae: 11.8117\n",
            "Epoch 334/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 8.3600 - mae: 8.3600\n",
            "Epoch 335/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.4833 - mae: 12.4833\n",
            "Epoch 336/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 32.2171 - mae: 32.2171\n",
            "Epoch 337/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 10.4477 - mae: 10.4477\n",
            "Epoch 338/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 19.6832 - mae: 19.6832\n",
            "Epoch 339/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 35.0762 - mae: 35.0762\n",
            "Epoch 340/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.4192 - mae: 10.4192\n",
            "Epoch 341/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7625 - mae: 9.7625\n",
            "Epoch 342/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.9500 - mae: 11.9500\n",
            "Epoch 343/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3943 - mae: 9.3943\n",
            "Epoch 344/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.6071 - mae: 5.6071\n",
            "Epoch 345/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 37.4876 - mae: 37.4876\n",
            "Epoch 346/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.8830 - mae: 16.8830\n",
            "Epoch 347/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.8748 - mae: 12.8748\n",
            "Epoch 348/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.1960 - mae: 8.1960\n",
            "Epoch 349/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.5568 - mae: 13.5568\n",
            "Epoch 350/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.4354 - mae: 15.4354\n",
            "Epoch 351/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 32.9626 - mae: 32.9626\n",
            "Epoch 352/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.2040 - mae: 14.2040\n",
            "Epoch 353/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 15.9196 - mae: 15.9196\n",
            "Epoch 354/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 19.0878 - mae: 19.0878\n",
            "Epoch 355/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 34.1178 - mae: 34.1178\n",
            "Epoch 356/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6798 - mae: 7.6798\n",
            "Epoch 357/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 25.2287 - mae: 25.2287\n",
            "Epoch 358/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 22.6759 - mae: 22.6759\n",
            "Epoch 359/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 8.8765 - mae: 8.8765\n",
            "Epoch 360/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 21.4709 - mae: 21.4709\n",
            "Epoch 361/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.6073 - mae: 20.6073\n",
            "Epoch 362/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 7.0611 - mae: 7.0611\n",
            "Epoch 363/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.8117 - mae: 25.8117\n",
            "Epoch 364/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 32.2247 - mae: 32.2247\n",
            "Epoch 365/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.0204 - mae: 10.0204\n",
            "Epoch 366/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6722 - mae: 9.6722\n",
            "Epoch 367/500\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 30.4171 - mae: 30.4171\n",
            "Epoch 368/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 10.5020 - mae: 10.5020\n",
            "Epoch 369/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.9909 - mae: 14.9909\n",
            "Epoch 370/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.6580 - mae: 14.6580\n",
            "Epoch 371/500\n",
            "2/2 [==============================] - 0s 15ms/step - loss: 23.3672 - mae: 23.3672\n",
            "Epoch 372/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 13.1025 - mae: 13.1025\n",
            "Epoch 373/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.2586 - mae: 9.2586\n",
            "Epoch 374/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.6648 - mae: 9.6648\n",
            "Epoch 375/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 13.0041 - mae: 13.0041\n",
            "Epoch 376/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.8863 - mae: 14.8863\n",
            "Epoch 377/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.7932 - mae: 14.7932\n",
            "Epoch 378/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.2751 - mae: 16.2751\n",
            "Epoch 379/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 20.8307 - mae: 20.8307\n",
            "Epoch 380/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.5317 - mae: 33.5317\n",
            "Epoch 381/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.2166 - mae: 8.2166\n",
            "Epoch 382/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.0960 - mae: 13.0960\n",
            "Epoch 383/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.3999 - mae: 8.3999\n",
            "Epoch 384/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.1283 - mae: 7.1283\n",
            "Epoch 385/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.9390 - mae: 10.9390\n",
            "Epoch 386/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 19.7654 - mae: 19.7654\n",
            "Epoch 387/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 24.8625 - mae: 24.8625\n",
            "Epoch 388/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 8.7422 - mae: 8.7422\n",
            "Epoch 389/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 5.9488 - mae: 5.9488\n",
            "Epoch 390/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 24.4400 - mae: 24.4400\n",
            "Epoch 391/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.9771 - mae: 5.9771\n",
            "Epoch 392/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 16.3250 - mae: 16.3250\n",
            "Epoch 393/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 6.0917 - mae: 6.0917\n",
            "Epoch 394/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 11.0963 - mae: 11.0963\n",
            "Epoch 395/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 14.9601 - mae: 14.9601\n",
            "Epoch 396/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 7.6462 - mae: 7.6462\n",
            "Epoch 397/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.7654 - mae: 8.7654\n",
            "Epoch 398/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 14.5991 - mae: 14.5991\n",
            "Epoch 399/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 11.3166 - mae: 11.3166\n",
            "Epoch 400/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 21.9080 - mae: 21.9080\n",
            "Epoch 401/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 14.8653 - mae: 14.8653\n",
            "Epoch 402/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.4970 - mae: 8.4970\n",
            "Epoch 403/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 10.3957 - mae: 10.3957\n",
            "Epoch 404/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.2556 - mae: 10.2556\n",
            "Epoch 405/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.3392 - mae: 6.3392\n",
            "Epoch 406/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 17.4602 - mae: 17.4602\n",
            "Epoch 407/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 11.4627 - mae: 11.4627\n",
            "Epoch 408/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.7294 - mae: 20.7294\n",
            "Epoch 409/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 31.3338 - mae: 31.3338\n",
            "Epoch 410/500\n",
            "2/2 [==============================] - 0s 14ms/step - loss: 9.2542 - mae: 9.2542\n",
            "Epoch 411/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 14.8621 - mae: 14.8621\n",
            "Epoch 412/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 21.7182 - mae: 21.7182\n",
            "Epoch 413/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.6615 - mae: 12.6615\n",
            "Epoch 414/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 6.0687 - mae: 6.0687\n",
            "Epoch 415/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.2201 - mae: 13.2201\n",
            "Epoch 416/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 27.4244 - mae: 27.4244\n",
            "Epoch 417/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 10.6407 - mae: 10.6407\n",
            "Epoch 418/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 12.8230 - mae: 12.8230\n",
            "Epoch 419/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.8836 - mae: 15.8836\n",
            "Epoch 420/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 24.7510 - mae: 24.7510\n",
            "Epoch 421/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 17.3753 - mae: 17.3753\n",
            "Epoch 422/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 7.8241 - mae: 7.8241\n",
            "Epoch 423/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 25.3789 - mae: 25.3789\n",
            "Epoch 424/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.1031 - mae: 15.1031\n",
            "Epoch 425/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.1643 - mae: 7.1643\n",
            "Epoch 426/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 20.3318 - mae: 20.3318\n",
            "Epoch 427/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.3283 - mae: 6.3283\n",
            "Epoch 428/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.9961 - mae: 12.9961\n",
            "Epoch 429/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.7869 - mae: 10.7869\n",
            "Epoch 430/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.4007 - mae: 11.4007\n",
            "Epoch 431/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 10.6152 - mae: 10.6152\n",
            "Epoch 432/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 11.4582 - mae: 11.4582\n",
            "Epoch 433/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.3851 - mae: 11.3851\n",
            "Epoch 434/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 30.3986 - mae: 30.3986\n",
            "Epoch 435/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 10.5052 - mae: 10.5052\n",
            "Epoch 436/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 28.8810 - mae: 28.8810\n",
            "Epoch 437/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 8.5916 - mae: 8.5916\n",
            "Epoch 438/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7378 - mae: 12.7378\n",
            "Epoch 439/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 33.6754 - mae: 33.6754\n",
            "Epoch 440/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0963 - mae: 15.0963\n",
            "Epoch 441/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.4813 - mae: 17.4813\n",
            "Epoch 442/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 22.3049 - mae: 22.3049\n",
            "Epoch 443/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.5841 - mae: 23.5841\n",
            "Epoch 444/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.0008 - mae: 11.0008\n",
            "Epoch 445/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.9175 - mae: 14.9175\n",
            "Epoch 446/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.9979 - mae: 17.9979\n",
            "Epoch 447/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.4482 - mae: 5.4482\n",
            "Epoch 448/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 10.0527 - mae: 10.0527\n",
            "Epoch 449/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.0052 - mae: 14.0052\n",
            "Epoch 450/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 16.7782 - mae: 16.7782\n",
            "Epoch 451/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.2937 - mae: 14.2937\n",
            "Epoch 452/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 30.6193 - mae: 30.6193\n",
            "Epoch 453/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 7.6541 - mae: 7.6541\n",
            "Epoch 454/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 28.1428 - mae: 28.1428\n",
            "Epoch 455/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 8.0017 - mae: 8.0017\n",
            "Epoch 456/500\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 10.3933 - mae: 10.3933\n",
            "Epoch 457/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.0242 - mae: 15.0242\n",
            "Epoch 458/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 16.5653 - mae: 16.5653\n",
            "Epoch 459/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 26.8566 - mae: 26.8566\n",
            "Epoch 460/500\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 12.4852 - mae: 12.4852\n",
            "Epoch 461/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.4784 - mae: 12.4784\n",
            "Epoch 462/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3186 - mae: 13.3186\n",
            "Epoch 463/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 29.5524 - mae: 29.5524\n",
            "Epoch 464/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.4664 - mae: 3.4664\n",
            "Epoch 465/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 15.2136 - mae: 15.2136\n",
            "Epoch 466/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 20.8327 - mae: 20.8327\n",
            "Epoch 467/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 30.5108 - mae: 30.5108\n",
            "Epoch 468/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.0597 - mae: 11.0597\n",
            "Epoch 469/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 12.8372 - mae: 12.8372\n",
            "Epoch 470/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 3.2398 - mae: 3.2398\n",
            "Epoch 471/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 16.6964 - mae: 16.6964\n",
            "Epoch 472/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.3883 - mae: 13.3883\n",
            "Epoch 473/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 15.2771 - mae: 15.2771\n",
            "Epoch 474/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 11.7448 - mae: 11.7448\n",
            "Epoch 475/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 16.4113 - mae: 16.4113\n",
            "Epoch 476/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 13.8785 - mae: 13.8785\n",
            "Epoch 477/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.6702 - mae: 30.6702\n",
            "Epoch 478/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 8.5880 - mae: 8.5880\n",
            "Epoch 479/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 10.7384 - mae: 10.7384\n",
            "Epoch 480/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 17.9051 - mae: 17.9051\n",
            "Epoch 481/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 15.8095 - mae: 15.8095\n",
            "Epoch 482/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 21.3054 - mae: 21.3054\n",
            "Epoch 483/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 25.3845 - mae: 25.3845\n",
            "Epoch 484/500\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 23.9815 - mae: 23.9815\n",
            "Epoch 485/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 5.7734 - mae: 5.7734\n",
            "Epoch 486/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.0010 - mae: 20.0010\n",
            "Epoch 487/500\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 14.0419 - mae: 14.0419\n",
            "Epoch 488/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 30.6088 - mae: 30.6088\n",
            "Epoch 489/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 11.9409 - mae: 11.9409\n",
            "Epoch 490/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 12.7352 - mae: 12.7352\n",
            "Epoch 491/500\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 23.6139 - mae: 23.6139\n",
            "Epoch 492/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.5365 - mae: 20.5365\n",
            "Epoch 493/500\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 4.9942 - mae: 4.9942\n",
            "Epoch 494/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 12.7986 - mae: 12.7986\n",
            "Epoch 495/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 13.3772 - mae: 13.3772\n",
            "Epoch 496/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 12.6727 - mae: 12.6727\n",
            "Epoch 497/500\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 17.6192 - mae: 17.6192\n",
            "Epoch 498/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 23.5629 - mae: 23.5629\n",
            "Epoch 499/500\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 9.3755 - mae: 9.3755\n",
            "Epoch 500/500\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.6316 - mae: 14.6316\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49861bef10>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make and plot some predictions\n",
        "y_preds_3 = model_3.predict(X_test)\n",
        "plot_predictions(predictions = y_preds_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "H1hw7sHcmoav",
        "outputId": "5e52599f-f40d-429e-e8ed-3004984814b1"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model trained for TOO LONG!   \n",
        "This, my friend, is called OVERFITTING. The model is too complex for the data set.\n",
        "\n",
        "For completness, let's carry on to evaluating the model."
      ],
      "metadata": {
        "id": "UDxtjf3nnAoF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculated model_3 evaluation metrics\n",
        "mae_3 = mae(y_test, y_preds_3)\n",
        "mse_3 = mse(y_test, y_preds_3)\n",
        "\n",
        "mae_3, mse_3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odWn67XCnY5N",
        "outputId": "4dd921cc-8fdc-4995-a346-cabd123026d3"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68.713615, 4808.0273)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Note:** Start with smaller experiments (small models) and make sure they work, then increase their scale, as necessary."
      ],
      "metadata": {
        "id": "qVcgddpdorLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Comparing the Results of the Experiment Conducted\n",
        "\n",
        "After running a few experiments, let's compare the results."
      ],
      "metadata": {
        "id": "pZlHZKv6oLdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare the model's results using a pandas DataFrame\n",
        "import pandas as pd\n",
        "\n",
        "model_results = [[\"model_1\", mae_1, mse_1],             # compile the models, mae, and mse into a matrix/tensor; \n",
        "                [\"model_2\", mae_2, mse_2],              \n",
        "                [\"model_3\", mae_3, mse_3]]\n",
        "\n",
        "all_results = pd.DataFrame(model_results, columns = [\"model\", \"mae\", \"mse\"])      # compile results in a pandas dataframe\n",
        "all_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bCM_gUU0oilz",
        "outputId": "9c85d9a0-9043-42db-8811-daf067b5d951"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-0d1af9bd-218f-4dd4-8dce-faa6691bd4a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>model_1</td>\n",
              "      <td>18.745327</td>\n",
              "      <td>353.573364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>model_2</td>\n",
              "      <td>3.196941</td>\n",
              "      <td>13.070143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>model_3</td>\n",
              "      <td>68.713615</td>\n",
              "      <td>4808.027344</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d1af9bd-218f-4dd4-8dce-faa6691bd4a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d1af9bd-218f-4dd4-8dce-faa6691bd4a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d1af9bd-218f-4dd4-8dce-faa6691bd4a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     model        mae          mse\n",
              "0  model_1  18.745327   353.573364\n",
              "1  model_2   3.196941    13.070143\n",
              "2  model_3  68.713615  4808.027344"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like `model_2` performed the best!"
      ],
      "metadata": {
        "id": "-NGwbrcXsiK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Review model_2's structure\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQLe5dkJqSHE",
        "outputId": "3e02e071-0228-4539-b31b-79cbaf34a539"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">  **Note:** One of the main goals should be to minimize the time between experiments. The more experiment completed, the more things one will figure out which DO NOT work. In return, one gets closer to figuring out what DOES work. \n",
        "\n",
        "Remember **Machine Learning Practicioner's Motto: \"experiment, experiment, experiment!\"**\n",
        "\n",
        "And... **\"If in doubt, run the code!\"**"
      ],
      "metadata": {
        "id": "fw1nTEYNsm2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tracking Experiments\n",
        "\n",
        "One really good habit in Machine Learning modelling is to track the results of the experiment.\n",
        "\n",
        "Also, when doing so, it can be tedious when running several experimental_functions_run_eagerly\n",
        "\n",
        "Luckily, there are tools to help!\n",
        "\n",
        "\n",
        " **Resource:** As one builds more models, look into using:\n",
        "\n",
        "* TensorBoard - a component of the TensorFlow library to help track modelling experiments.\n",
        "* Weights & Biases - a tool for tracking all kinds of Machine Learning experiments (plugs straight into TensorBoard).\n"
      ],
      "metadata": {
        "id": "KooqaPrvtdAK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Models\n",
        "\n",
        "Saving models allows the use of them outside of Google Colab (or wherever the model was trained) such as in a web application or a mobile app.\n",
        "\n",
        "There are 2 main formats in which models are saved:\n",
        "\n",
        "1. The `SaveModel` format (the Default)\n",
        "2. The `HDF5` format"
      ],
      "metadata": {
        "id": "_6q_3N1BuRHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model using SaveModel format\n",
        "model_2.save(\"best_model_SavedModel_format\")    # Outputs a file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyGLOdiaucTT",
        "outputId": "f23da6d6-2105-457b-f9c7-34f19c99cc37"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: best_model_SavedModel_format/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model uing HDF5 format\n",
        "model_2.save(\"best_model_HDF5_format.h5\")       # Outputs a single file"
      ],
      "metadata": {
        "id": "X4IDs75OvXQ7"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in a Saved Model"
      ],
      "metadata": {
        "id": "P1F5jxgPvz-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the SavedModel format model\n",
        "loaded_SavedModel_format = tf.keras.models.load_model(\"/content/best_model_SavedModel_format\")     # string is the copied path from the folder of the saved model\n",
        "loaded_SavedModel_format.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2NjoOsowOZu",
        "outputId": "fdeb5cab-599b-40f0-c187-90c4b71bf0d8"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the models are the same structure\n",
        "loaded_SavedModel_format.summary() == model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oms7ZmXUwm6Q",
        "outputId": "ef7e51dd-344c-4eb8-a46d-935f36abc359"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_2 predictions with SavedModel format model predictions\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_SavedModel_format_preds = loaded_SavedModel_format.predict(X_test)\n",
        "\n",
        "model_2_preds == loaded_SavedModel_format_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySHxxCO1wr34",
        "outputId": "6febce8c-e497-4a8d-85c2-3024e89f9076"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the model using the .h5 format\n",
        "loaded_h5_model = tf.keras.models.load_model(\"/content/best_model_HDF5_format.h5\")\n",
        "loaded_h5_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRNS9JTsxLMH",
        "outputId": "2abc1c78-4b44-437c-c2a3-0dfee1d2ad76"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the models are the same structure\n",
        "loaded_h5_model.summary() == model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0QOtmphz6FG",
        "outputId": "0fc73070-d6f8-4c97-dd4a-464ed08aefed"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare model_2 predictions with SavedModel format model predictions\n",
        "model_2_preds = model_2.predict(X_test)\n",
        "loaded_h5_model_preds = loaded_h5_model.predict(X_test)\n",
        "\n",
        "model_2_preds == loaded_h5_model_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU8DGVGK0CPi",
        "outputId": "656cfc0b-6248-4487-eb4b-ba1689412cb4"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's functionize this step for checking loaded saved models with a model of one's choice"
      ],
      "metadata": {
        "id": "hr3s49qx0POO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_loaded_model(model, loaded_model, test_data):\n",
        "  \"\"\"\n",
        "  Checks that the loaded model has the same structure as the model of interest.\n",
        "  Also, compares the loaded model's predictions with the model of interest.\n",
        "  \"\"\"\n",
        "  # Check that the models are the same structure\n",
        "  a = loaded_model.summary() == model.summary()\n",
        "\n",
        "  # Compare model predictions with loaded model predictions\n",
        "  model_preds = model.predict(test_data)\n",
        "  loaded_model_preds = loaded_model.predict(test_data)\n",
        "  \n",
        "  b = model_2_preds == loaded_h5_model_preds\n",
        "\n",
        "  print(\"Model and Loaded Model have the same structure: \", a)\n",
        "  print(\"Model and Loaded Model make the same predictions: \", b)"
      ],
      "metadata": {
        "id": "Xx_4sFcf0pj6"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_loaded_model(model_2, loaded_h5_model, X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgxKuB292jXF",
        "outputId": "d2863935-ecde-4bd7-f545-178020c904c0"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 10)                20        \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 31\n",
            "Trainable params: 31\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model and Loaded Model have the same structure:  True\n",
            "Model and Loaded Model make the same predictions:  [[ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]\n",
            " [ True]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download a Model (or any other file) from Google Colab\n",
        "\n",
        "To dowload files from Google Colab:\n",
        "\n",
        "1. Go to the \"Files\" tab, right click, then \"Download\".\n",
        "2. Use code (see cell below).\n",
        "3. Save it to Google Drive by connecting to Google Drive and coying it there (see 2nd code cell below)."
      ],
      "metadata": {
        "id": "9Psoz9sS2p51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download a file from Google Colab\n",
        "from google.colab import files\n",
        "files.download(\"/content/best_model_HDF5_format.h5\")   # file path can be obtained by right clicking on the Google Colab file, then click \"Copy Path\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "D9lEEauZ3wxZ",
        "outputId": "8441f3dd-cbbf-443b-ad71-18bc015c43c7"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_da4ba4e3-610a-43ae-8274-6597013042a5\", \"best_model_HDF5_format.h5\", 17872)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save a file from Google Colab to Google Drive (requires mounting Google Drive)\n",
        "!cp /content/best_model_HDF5_format.h5 /content/drive/MyDrive/ZTM_TensorFlow_Course"
      ],
      "metadata": {
        "id": "tbNQaO2G4P9l"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check within the saved folder for the file\n",
        "!ls /content/drive/MyDrive/ZTM_TensorFlow_Course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ff-Va5V5LLs",
        "outputId": "2e65aa3e-5bfc-41ea-e379-847f0a1ab4ff"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_HDF5_format.h5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Larger Example\n",
        "\n",
        "**Medical Cost Personal Datasets**\n",
        "> Kaggle Competition:  https://www.kaggle.com/mirichoi0218/insurance\n",
        "\n",
        ">**Regression Analysis** - a set of statistical processes for estimating the relationship between a dependent variable (aka outcome variable/prediction) and one or more independent variables (aka predictors/features)."
      ],
      "metadata": {
        "id": "lsRV-u8T5tk6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import the requried libraries\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "FGp2i1br6NU5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in the insurance data set\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "rTFxltXV6OjB",
        "outputId": "303df207-601b-4a48-fc78-678169308b20"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-eb335f44-0eb0-4884-a00f-b41079ad82bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1333</th>\n",
              "      <td>50</td>\n",
              "      <td>male</td>\n",
              "      <td>30.970</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>10600.54830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>31.920</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northeast</td>\n",
              "      <td>2205.98080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1335</th>\n",
              "      <td>18</td>\n",
              "      <td>female</td>\n",
              "      <td>36.850</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1629.83350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1336</th>\n",
              "      <td>21</td>\n",
              "      <td>female</td>\n",
              "      <td>25.800</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>southwest</td>\n",
              "      <td>2007.94500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1337</th>\n",
              "      <td>61</td>\n",
              "      <td>female</td>\n",
              "      <td>29.070</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>northwest</td>\n",
              "      <td>29141.36030</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1338 rows  7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb335f44-0eb0-4884-a00f-b41079ad82bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eb335f44-0eb0-4884-a00f-b41079ad82bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eb335f44-0eb0-4884-a00f-b41079ad82bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      age     sex     bmi  children smoker     region      charges\n",
              "0      19  female  27.900         0    yes  southwest  16884.92400\n",
              "1      18    male  33.770         1     no  southeast   1725.55230\n",
              "2      28    male  33.000         3     no  southeast   4449.46200\n",
              "3      33    male  22.705         0     no  northwest  21984.47061\n",
              "4      32    male  28.880         0     no  northwest   3866.85520\n",
              "...   ...     ...     ...       ...    ...        ...          ...\n",
              "1333   50    male  30.970         3     no  northwest  10600.54830\n",
              "1334   18  female  31.920         0     no  northeast   2205.98080\n",
              "1335   18  female  36.850         0     no  southeast   1629.83350\n",
              "1336   21  female  25.800         0     no  southwest   2007.94500\n",
              "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
              "\n",
              "[1338 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When there is categorical data (i.e. sex, region), there is a need to create numerical encoding.\n",
        "\n",
        "**One Hot Encoding on Pandas DataFrame**\n",
        "> `get_dummies` -> convert categorical variable into dummy/indicator variable; aka one hot encoding"
      ],
      "metadata": {
        "id": "q1RHN6Ud8Z6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-hot encode the DataFrame so that it is all numbers\n",
        "insurance_one_hot = pd.get_dummies(insurance)\n",
        "insurance_one_hot.head()           # will output only the top 5 lines"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "6C2Gyjgw-L1v",
        "outputId": "82d32b2f-1925-49f6-86b6-27cfebb8c6b0"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5e3676b9-9108-4c1e-8b63-d2e7099c9f7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>charges</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>smoker_no</th>\n",
              "      <th>smoker_yes</th>\n",
              "      <th>region_northeast</th>\n",
              "      <th>region_northwest</th>\n",
              "      <th>region_southeast</th>\n",
              "      <th>region_southwest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>16884.92400</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>1725.55230</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>4449.46200</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>21984.47061</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>3866.85520</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e3676b9-9108-4c1e-8b63-d2e7099c9f7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e3676b9-9108-4c1e-8b63-d2e7099c9f7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e3676b9-9108-4c1e-8b63-d2e7099c9f7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              "0   19  27.900         0  ...                 0                 0                 1\n",
              "1   18  33.770         1  ...                 0                 1                 0\n",
              "2   28  33.000         3  ...                 0                 1                 0\n",
              "3   33  22.705         0  ...                 1                 0                 0\n",
              "4   32  28.880         0  ...                 1                 0                 0\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Create X and y values (features and labels, respectively)\n",
        " X = insurance_one_hot.drop(\"charges\", axis = 1)      # will save all the columns but the \"charges\" column from the insurance datafram into variable \"X\"\n",
        " y = insurance_one_hot[\"charges\"]                     # save the column \"charges\" to variable \"y\"\n",
        " X.head(), y.head()                                   # review \"X\" and \"y\" dataframes to check"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fC4XKTjo-nrf",
        "outputId": "d386dfa0-040c-44b5-8380-015db1a29f4b"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(   age     bmi  children  ...  region_northwest  region_southeast  region_southwest\n",
              " 0   19  27.900         0  ...                 0                 0                 1\n",
              " 1   18  33.770         1  ...                 0                 1                 0\n",
              " 2   28  33.000         3  ...                 0                 1                 0\n",
              " 3   33  22.705         0  ...                 1                 0                 0\n",
              " 4   32  28.880         0  ...                 1                 0                 0\n",
              " \n",
              " [5 rows x 11 columns], 0    16884.92400\n",
              " 1     1725.55230\n",
              " 2     4449.46200\n",
              " 3    21984.47061\n",
              " 4     3866.85520\n",
              " Name: charges, dtype: float64)"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Create training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, \n",
        "                                                    y,\n",
        "                                                    test_size=0.2,           # test size = 20% of the data; thus training is 80% of data\n",
        "                                                    random_state=42)         # allow for reproducibility\n",
        "len(X), len(X_train), len(X_test)                  # Outputs the total quantity of \"X\" dataframe, then the quantities between the training and test data sets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rt24_lxA_bOH",
        "outputId": "7d727a37-50a3-4582-bdba-f719f1a7f237"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1338, 1070, 268)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Build a neural nework (sort of like model_2)\n",
        " tf.random.set_seed(42)            # allow for reproducibility of randomization\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model = tf.keras.Sequential([\n",
        "                  tf.keras.layers.Dense(10),    # first layer with 10 hidden variables\n",
        "                  tf.keras.layers.Dense(1)      # second layer with 1 hidden variable\n",
        "                   ])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model.compile(loss=tf.keras.losses.mae,\n",
        "                        optimizer = tf.keras.optimizers.SGD(),\n",
        "                        metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model.fit(X_train, y_train, epochs=100)    # do not reformat into tensors, bc pandas is built on NumPy arrays and knows what to do automatically"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UT7QhMw__cdF",
        "outputId": "9dfd1f16-566f-4efc-bd3b-c8769051a023"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 8637.1006 - mae: 8637.1006\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7886.7759 - mae: 7886.7759\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7558.1470 - mae: 7558.1470\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7792.0220 - mae: 7792.0220\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7748.3887 - mae: 7748.3887\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7595.3940 - mae: 7595.3940\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7589.9844 - mae: 7589.9844\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7698.5576 - mae: 7698.5576\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.7778 - mae: 7496.7778\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7493.1743 - mae: 7493.1743\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7769.7295 - mae: 7769.7295\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7706.9028 - mae: 7706.9028\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7687.7231 - mae: 7687.7231\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7689.9004 - mae: 7689.9004\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7393.5327 - mae: 7393.5327\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7780.6987 - mae: 7780.6987\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7578.5098 - mae: 7578.5098\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7750.8354 - mae: 7750.8354\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7739.2144 - mae: 7739.2144\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7875.0654 - mae: 7875.0654\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7466.6768 - mae: 7466.6768\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7941.2329 - mae: 7941.2329\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7640.2725 - mae: 7640.2725\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7539.2671 - mae: 7539.2671\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7619.9653 - mae: 7619.9653\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7644.1719 - mae: 7644.1719\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7709.0371 - mae: 7709.0371\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7366.8662 - mae: 7366.8662\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7444.3154 - mae: 7444.3154\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7616.4077 - mae: 7616.4077\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7686.3853 - mae: 7686.3853\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7548.0977 - mae: 7548.0977\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7501.5532 - mae: 7501.5532\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7363.4160 - mae: 7363.4160\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7295.4478 - mae: 7295.4478\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7569.8813 - mae: 7569.8813\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7548.1997 - mae: 7548.1997\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7424.3975 - mae: 7424.3975\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7529.7734 - mae: 7529.7734\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7467.3232 - mae: 7467.3232\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7635.9292 - mae: 7635.9292\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7536.8398 - mae: 7536.8398\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7616.5859 - mae: 7616.5859\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7439.4941 - mae: 7439.4941\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7538.0151 - mae: 7538.0151\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7415.1470 - mae: 7415.1470\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7420.6938 - mae: 7420.6938\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7509.9839 - mae: 7509.9839\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7541.1133 - mae: 7541.1133\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7467.8643 - mae: 7467.8643\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7389.3560 - mae: 7389.3560\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7499.7749 - mae: 7499.7749\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7523.9282 - mae: 7523.9282\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7243.3115 - mae: 7243.3115\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7429.5864 - mae: 7429.5864\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7313.3999 - mae: 7313.3999\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7526.3877 - mae: 7526.3877\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7542.2666 - mae: 7542.2666\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7576.9277 - mae: 7576.9277\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7546.4048 - mae: 7546.4048\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7351.2261 - mae: 7351.2261\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7302.1436 - mae: 7302.1436\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7393.0879 - mae: 7393.0879\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7442.2881 - mae: 7442.2881\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7492.6782 - mae: 7492.6782\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7561.9165 - mae: 7561.9165\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7340.5137 - mae: 7340.5137\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7496.0845 - mae: 7496.0845\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7617.0303 - mae: 7617.0303\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7641.1948 - mae: 7641.1948\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7084.2744 - mae: 7084.2744\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7240.4902 - mae: 7240.4902\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7283.4888 - mae: 7283.4888\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7335.5083 - mae: 7335.5083\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7275.6392 - mae: 7275.6392\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7313.1860 - mae: 7313.1860\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7485.7588 - mae: 7485.7588\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7352.2803 - mae: 7352.2803\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7520.5703 - mae: 7520.5703\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7279.3779 - mae: 7279.3779\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7273.8477 - mae: 7273.8477\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7176.5215 - mae: 7176.5215\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7425.6289 - mae: 7425.6289\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7403.1294 - mae: 7403.1294\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7356.0088 - mae: 7356.0088\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7484.7271 - mae: 7484.7271\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7217.6074 - mae: 7217.6074\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7261.0000 - mae: 7261.0000\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7134.1562 - mae: 7134.1562\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7083.4360 - mae: 7083.4360\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7254.1782 - mae: 7254.1782\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7268.7456 - mae: 7268.7456\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7470.5220 - mae: 7470.5220\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7210.9536 - mae: 7210.9536\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7395.6816 - mae: 7395.6816\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7328.0884 - mae: 7328.0884\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 1ms/step - loss: 7230.4380 - mae: 7230.4380\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7261.3936 - mae: 7261.3936\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7342.5684 - mae: 7342.5684\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7106.1714 - mae: 7106.1714\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49842ba910>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the results of the insurance model on the test data\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfj0g5RTBhbL",
        "outputId": "67c6b2cc-95aa-4869-a928-840995782f41"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the training dependent variable to see how the mae stacks up against it\n",
        "y_train.mean(), y_train.median()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cydNBUGnBiUY",
        "outputId": "d71c55b7-15fe-4cf8-da29-d793c34ff488"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13346.089736364489, 9575.4421)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Right now, it looks like the model is NOT performing well \n",
        "\n",
        "...Let's try to improve it!\n",
        "\n",
        "To (try) to improve the model, let's run 2 experiments:\n",
        "1. Add an extra layer with more hidden units and use the Adam optimizer\n",
        "2. Same as the above model in #1 (`insurance_model_2`), but train for a longer duration (200 epochs)"
      ],
      "metadata": {
        "id": "0MSRAZ7nL3in"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seet\n",
        "tf.random.set_seed(42)    # to allow for reproducibility\n",
        "\n",
        "# 1. Create the model (3 layers, with 100, 10 and 1 hidden units, respectively)\n",
        "insurance_model_2 = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Dense(100),\n",
        "                    tf.keras.layers.Dense(10),\n",
        "                    tf.keras.layers.Dense(1)                     \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_2.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer = tf.keras.optimizers.Adam(),\n",
        "                          metrics=['mae']\n",
        ")\n",
        "\n",
        "# 3. Fit the model\n",
        "insurance_model_2.fit(X_train, y_train, epochs=100)   # set verbose=0 so the output shown isn't massive           "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1g6aJABMYDm",
        "outputId": "af148063-1465-4927-a45d-92e7440844f5"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12055.7510 - mae: 12055.7510\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7528.8408 - mae: 7528.8408\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9180 - mae: 7368.9180\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7024.3501 - mae: 7024.3501\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6652.4614 - mae: 6652.4614\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1006 - mae: 6618.1006\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6530.0444 - mae: 6530.0444\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6310.1948 - mae: 6310.1948\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0718 - mae: 5963.0718\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f498392c590>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the larger model\n",
        "insurance_model_2.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlgFEa1Qt0wX",
        "outputId": "4ab6a5d8-119a-49d0-d866-806d5bc58947"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4924.34765625, 4924.34765625]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare with the first model\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2y4sOYUueA-",
        "outputId": "60d99969-57fe-41e4-fd47-69da3f836bf4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "4924/7023"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOnwqjvZvs6G",
        "outputId": "0c23cc4a-cdd0-48e7-babe-a85982c57628"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7011248754093692"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)     # to allow for reproducibility\n",
        "\n",
        "# 1. Create the model (same as the above)\n",
        "insurance_model_3 = tf.keras.Sequential([\n",
        "                    tf.keras.layers.Dense(100),\n",
        "                    tf.keras.layers.Dense(10),\n",
        "                    tf.keras.layers.Dense(1)                    \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_3.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer = tf.keras.optimizers.Adam(),\n",
        "                          metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model\n",
        "history = insurance_model_3.fit(X_train, y_train, epochs=200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PAH0lw2IvzXH",
        "outputId": "32f3dd45-1954-4987-a58b-37cc02a4fa12"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
            "Epoch 2/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13104.4297 - mae: 13104.4297\n",
            "Epoch 3/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
            "Epoch 4/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12055.7510 - mae: 12055.7510\n",
            "Epoch 5/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10905.8154 - mae: 10905.8154\n",
            "Epoch 6/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9457.7217 - mae: 9457.7217\n",
            "Epoch 7/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8147.6543 - mae: 8147.6543\n",
            "Epoch 8/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7528.8408 - mae: 7528.8408\n",
            "Epoch 9/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7429.1528 - mae: 7429.1528\n",
            "Epoch 10/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7409.0811 - mae: 7409.0811\n",
            "Epoch 11/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
            "Epoch 12/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7368.9180 - mae: 7368.9180\n",
            "Epoch 13/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7348.5195 - mae: 7348.5195\n",
            "Epoch 14/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
            "Epoch 15/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7307.5815 - mae: 7307.5815\n",
            "Epoch 16/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
            "Epoch 17/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
            "Epoch 18/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
            "Epoch 19/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7220.5068 - mae: 7220.5068\n",
            "Epoch 20/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7197.1978 - mae: 7197.1978\n",
            "Epoch 21/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7179.0195 - mae: 7179.0195\n",
            "Epoch 22/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
            "Epoch 23/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7126.4639 - mae: 7126.4639\n",
            "Epoch 24/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7101.9199 - mae: 7101.9199\n",
            "Epoch 25/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
            "Epoch 26/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7052.3291 - mae: 7052.3291\n",
            "Epoch 27/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7024.3501 - mae: 7024.3501\n",
            "Epoch 28/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
            "Epoch 29/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
            "Epoch 30/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
            "Epoch 31/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6911.7280 - mae: 6911.7280\n",
            "Epoch 32/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6884.0205 - mae: 6884.0205\n",
            "Epoch 33/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6853.4648 - mae: 6853.4648\n",
            "Epoch 34/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
            "Epoch 35/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
            "Epoch 36/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
            "Epoch 37/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
            "Epoch 38/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6689.7158 - mae: 6689.7158\n",
            "Epoch 39/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6652.4614 - mae: 6652.4614\n",
            "Epoch 40/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6618.1006 - mae: 6618.1006\n",
            "Epoch 41/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6585.8643 - mae: 6585.8643\n",
            "Epoch 42/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
            "Epoch 43/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6530.0444 - mae: 6530.0444\n",
            "Epoch 44/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
            "Epoch 45/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
            "Epoch 46/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
            "Epoch 47/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6458.8979 - mae: 6458.8979\n",
            "Epoch 48/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
            "Epoch 49/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6430.9639 - mae: 6430.9639\n",
            "Epoch 50/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6417.7510 - mae: 6417.7510\n",
            "Epoch 51/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6403.2759 - mae: 6403.2759\n",
            "Epoch 52/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6392.4141 - mae: 6392.4141\n",
            "Epoch 53/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6378.7451 - mae: 6378.7451\n",
            "Epoch 54/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6364.9131 - mae: 6364.9131\n",
            "Epoch 55/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
            "Epoch 56/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6337.6602 - mae: 6337.6602\n",
            "Epoch 57/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
            "Epoch 58/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 6310.1948 - mae: 6310.1948\n",
            "Epoch 59/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6295.6035 - mae: 6295.6035\n",
            "Epoch 60/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
            "Epoch 61/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
            "Epoch 62/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
            "Epoch 63/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6234.9292 - mae: 6234.9292\n",
            "Epoch 64/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6218.0430 - mae: 6218.0430\n",
            "Epoch 65/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
            "Epoch 66/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6183.9590 - mae: 6183.9590\n",
            "Epoch 67/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
            "Epoch 68/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6148.8398 - mae: 6148.8398\n",
            "Epoch 69/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6132.5981 - mae: 6132.5981\n",
            "Epoch 70/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
            "Epoch 71/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
            "Epoch 72/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
            "Epoch 73/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6059.4873 - mae: 6059.4873\n",
            "Epoch 74/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6031.3848 - mae: 6031.3848\n",
            "Epoch 75/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6010.3350 - mae: 6010.3350\n",
            "Epoch 76/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5995.2178 - mae: 5995.2178\n",
            "Epoch 77/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5963.0718 - mae: 5963.0718\n",
            "Epoch 78/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
            "Epoch 79/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
            "Epoch 80/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
            "Epoch 81/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5861.6992 - mae: 5861.6992\n",
            "Epoch 82/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5834.3066 - mae: 5834.3066\n",
            "Epoch 83/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5805.8237 - mae: 5805.8237\n",
            "Epoch 84/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5772.3232 - mae: 5772.3232\n",
            "Epoch 85/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
            "Epoch 86/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5711.3477 - mae: 5711.3477\n",
            "Epoch 87/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5674.5215 - mae: 5674.5215\n",
            "Epoch 88/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5639.4927 - mae: 5639.4927\n",
            "Epoch 89/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5600.6655 - mae: 5600.6655\n",
            "Epoch 90/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
            "Epoch 91/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
            "Epoch 92/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5474.1250 - mae: 5474.1250\n",
            "Epoch 93/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
            "Epoch 94/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
            "Epoch 95/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
            "Epoch 96/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
            "Epoch 97/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
            "Epoch 98/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5170.9360 - mae: 5170.9360\n",
            "Epoch 99/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
            "Epoch 100/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5059.8643 - mae: 5059.8643\n",
            "Epoch 101/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4987.6191 - mae: 4987.6191\n",
            "Epoch 102/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4915.2910 - mae: 4915.2910\n",
            "Epoch 103/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4847.3599 - mae: 4847.3599\n",
            "Epoch 104/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4768.0151 - mae: 4768.0151\n",
            "Epoch 105/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4683.4727 - mae: 4683.4727\n",
            "Epoch 106/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4600.5054 - mae: 4600.5054\n",
            "Epoch 107/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4513.1436 - mae: 4513.1436\n",
            "Epoch 108/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4422.2983 - mae: 4422.2983\n",
            "Epoch 109/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4339.9600 - mae: 4339.9600\n",
            "Epoch 110/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4254.3916 - mae: 4254.3916\n",
            "Epoch 111/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 4173.1797 - mae: 4173.1797\n",
            "Epoch 112/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4102.2939 - mae: 4102.2939\n",
            "Epoch 113/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4031.9592 - mae: 4031.9592\n",
            "Epoch 114/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3986.0220 - mae: 3986.0220\n",
            "Epoch 115/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3943.2346 - mae: 3943.2346\n",
            "Epoch 116/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3918.8977 - mae: 3918.8977\n",
            "Epoch 117/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3895.5610 - mae: 3895.5610\n",
            "Epoch 118/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3869.5679 - mae: 3869.5679\n",
            "Epoch 119/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3850.2136 - mae: 3850.2136\n",
            "Epoch 120/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3834.7349 - mae: 3834.7349\n",
            "Epoch 121/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3827.0952 - mae: 3827.0952\n",
            "Epoch 122/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3821.6382 - mae: 3821.6382\n",
            "Epoch 123/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3813.8315 - mae: 3813.8315\n",
            "Epoch 124/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3805.7307 - mae: 3805.7307\n",
            "Epoch 125/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3794.7090 - mae: 3794.7090\n",
            "Epoch 126/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3804.4946 - mae: 3804.4946\n",
            "Epoch 127/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3796.0596 - mae: 3796.0596\n",
            "Epoch 128/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3791.0422 - mae: 3791.0422\n",
            "Epoch 129/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3800.0696 - mae: 3800.0696\n",
            "Epoch 130/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3788.5005 - mae: 3788.5005\n",
            "Epoch 131/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3780.8442 - mae: 3780.8442\n",
            "Epoch 132/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5413 - mae: 3774.5413\n",
            "Epoch 133/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3771.0156 - mae: 3771.0156\n",
            "Epoch 134/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3769.3762 - mae: 3769.3762\n",
            "Epoch 135/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3766.7610 - mae: 3766.7610\n",
            "Epoch 136/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3765.5508 - mae: 3765.5508\n",
            "Epoch 137/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3774.5032 - mae: 3774.5032\n",
            "Epoch 138/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3785.3909 - mae: 3785.3909\n",
            "Epoch 139/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3761.1299 - mae: 3761.1299\n",
            "Epoch 140/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3764.1753 - mae: 3764.1753\n",
            "Epoch 141/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3763.9250 - mae: 3763.9250\n",
            "Epoch 142/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3762.7959 - mae: 3762.7959\n",
            "Epoch 143/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3754.4397 - mae: 3754.4397\n",
            "Epoch 144/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3347 - mae: 3750.3347\n",
            "Epoch 145/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.4006 - mae: 3750.4006\n",
            "Epoch 146/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3755.4736 - mae: 3755.4736\n",
            "Epoch 147/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3750.3223 - mae: 3750.3223\n",
            "Epoch 148/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3758.1089 - mae: 3758.1089\n",
            "Epoch 149/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3743.4858 - mae: 3743.4858\n",
            "Epoch 150/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3738.5342 - mae: 3738.5342\n",
            "Epoch 151/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3740.1384 - mae: 3740.1384\n",
            "Epoch 152/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3742.4954 - mae: 3742.4954\n",
            "Epoch 153/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3744.4399 - mae: 3744.4399\n",
            "Epoch 154/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1824 - mae: 3737.1824\n",
            "Epoch 155/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3737.6541 - mae: 3737.6541\n",
            "Epoch 156/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3737.1663 - mae: 3737.1663\n",
            "Epoch 157/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3733.1101 - mae: 3733.1101\n",
            "Epoch 158/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3729.5813 - mae: 3729.5813\n",
            "Epoch 159/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3725.9053 - mae: 3725.9053\n",
            "Epoch 160/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3733.2817 - mae: 3733.2817\n",
            "Epoch 161/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3728.2559 - mae: 3728.2559\n",
            "Epoch 162/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3724.5825 - mae: 3724.5825\n",
            "Epoch 163/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3723.0806 - mae: 3723.0806\n",
            "Epoch 164/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3726.9475 - mae: 3726.9475\n",
            "Epoch 165/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3716.5430 - mae: 3716.5430\n",
            "Epoch 166/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.9155 - mae: 3721.9155\n",
            "Epoch 167/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3721.1814 - mae: 3721.1814\n",
            "Epoch 168/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3715.2456 - mae: 3715.2456\n",
            "Epoch 169/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.9756 - mae: 3713.9756\n",
            "Epoch 170/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.9922 - mae: 3707.9922\n",
            "Epoch 171/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3707.4158 - mae: 3707.4158\n",
            "Epoch 172/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.6833 - mae: 3710.6833\n",
            "Epoch 173/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3703.3618 - mae: 3703.3618\n",
            "Epoch 174/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.9385 - mae: 3710.9385\n",
            "Epoch 175/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3713.0417 - mae: 3713.0417\n",
            "Epoch 176/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3705.0571 - mae: 3705.0571\n",
            "Epoch 177/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3698.9333 - mae: 3698.9333\n",
            "Epoch 178/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.9983 - mae: 3697.9983\n",
            "Epoch 179/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3704.9150 - mae: 3704.9150\n",
            "Epoch 180/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3710.3679 - mae: 3710.3679\n",
            "Epoch 181/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.6482 - mae: 3696.6482\n",
            "Epoch 182/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3692.7329 - mae: 3692.7329\n",
            "Epoch 183/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3691.1655 - mae: 3691.1655\n",
            "Epoch 184/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3699.2437 - mae: 3699.2437\n",
            "Epoch 185/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.2480 - mae: 3693.2480\n",
            "Epoch 186/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3696.1387 - mae: 3696.1387\n",
            "Epoch 187/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3687.8640 - mae: 3687.8640\n",
            "Epoch 188/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3693.3562 - mae: 3693.3562\n",
            "Epoch 189/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.7324 - mae: 3682.7324\n",
            "Epoch 190/200\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3683.2891 - mae: 3683.2891\n",
            "Epoch 191/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3697.6536 - mae: 3697.6536\n",
            "Epoch 192/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3684.6665 - mae: 3684.6665\n",
            "Epoch 193/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3675.5154 - mae: 3675.5154\n",
            "Epoch 194/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.3923 - mae: 3676.3923\n",
            "Epoch 195/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3672.8452 - mae: 3672.8452\n",
            "Epoch 196/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.0283 - mae: 3682.0283\n",
            "Epoch 197/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.7961 - mae: 3665.7961\n",
            "Epoch 198/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3671.7419 - mae: 3671.7419\n",
            "Epoch 199/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3680.5464 - mae: 3680.5464\n",
            "Epoch 200/200\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3665.6401 - mae: 3665.6401\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the third model\n",
        "insurance_model_3.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "omTAv4nSxOvN",
        "outputId": "d01c8445-7a66-4554-b13e-67d8eba1fe56"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3491.2961 - mae: 3491.2961\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3491.296142578125, 3491.296142578125]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Review the first model's evaluation metric\n",
        "insurance_model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkOG15MwxnfZ",
        "outputId": "7afb4201-c161-4ec2-b6e3-489c55255d94"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 7023.3291 - mae: 7023.3291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[7023.3291015625, 7023.3291015625]"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot history (also known as a loss curve or a training curve)\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.ylabel(\"loss\")\n",
        "plt.xlabel(\"epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8YGn68aixs4V",
        "outputId": "92e603ea-e720-48ae-c8b6-923817b396ea"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot helps to visualize how the model is learning and how the loss and mae values decrease as the time duration increases (hopefully!)"
      ],
      "metadata": {
        "id": "-9M86PzKyE28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Question:** How long should you train for? \n",
        "\n",
        "It depends. Really...it depends on the problem.\n",
        "\n",
        "However, this question is often asked. Therefore, TensorFlow has a solution! It is called the `EarlyStopping` callback (https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/EarlyStopping), which is a TensorFlow component that  is added to the model to stop training once it stops improving a certain metric."
      ],
      "metadata": {
        "id": "4kJxGCbCyaGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data (Normalization and Standardization)\n",
        "\n",
        "In terms of scaling values, neural networks tend to prefer normalization. \n",
        "\n",
        " **Resource:** https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "\n",
        "> **Feature Scaling**:\n",
        ">> * Scale (`MinMaxScaler`) - converts all values to between 0 and 1, while preserving the original distribution; use as a default scaler with neural networks\n",
        ">> * Standardization (`StandardScaler`) - removed the mean and divides each value by the standard deviation; transform a feature to have close to normal distribution (caution: this reduced the effect of outliers)"
      ],
      "metadata": {
        "id": "LaHrq1yWyzxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "# Read in the insurance dataframe\n",
        "insurance = pd.read_csv(\"https://raw.githubusercontent.com/stedy/Machine-Learning-with-R-datasets/master/insurance.csv\")\n",
        "insurance.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SevvD7x931fm",
        "outputId": "c3905baf-6de8-453b-d882-5b40fedeb4a2"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-01760d19-6f55-43ef-8a95-915f78212f62\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.900</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.92400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.770</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.55230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.000</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.46200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33</td>\n",
              "      <td>male</td>\n",
              "      <td>22.705</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>21984.47061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>male</td>\n",
              "      <td>28.880</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "      <td>northwest</td>\n",
              "      <td>3866.85520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01760d19-6f55-43ef-8a95-915f78212f62')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01760d19-6f55-43ef-8a95-915f78212f62 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01760d19-6f55-43ef-8a95-915f78212f62');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   age     sex     bmi  children smoker     region      charges\n",
              "0   19  female  27.900         0    yes  southwest  16884.92400\n",
              "1   18    male  33.770         1     no  southeast   1725.55230\n",
              "2   28    male  33.000         3     no  southeast   4449.46200\n",
              "3   33    male  22.705         0     no  northwest  21984.47061\n",
              "4   32    male  28.880         0     no  northwest   3866.85520"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To prepare the data, borrow a few classes from Scikit-Learn."
      ],
      "metadata": {
        "id": "u2IcOp8xzymu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import tensorflow_probability as tfp\n",
        "\n",
        "# Create a column transformer\n",
        "ct = make_column_transformer(\n",
        "    (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),        # turn all values in these columns between 0 and 1\n",
        "    (OneHotEncoder(handle_unknown=\"ignore\"), [\"sex\", \"smoker\", \"region\"])   # ignore the columns not identified here for one-hot encoding\n",
        ")\n",
        "\n",
        "# Create X and y \n",
        "X = insurance.drop(\"charges\", axis=1)     # all columns from insurance dataframe excluding \"charges\"\n",
        "y = insurance[\"charges\"]          # \"charges\" column is the prediction columns\n",
        "\n",
        "# Build the train and test data sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42)   # test: 20%, train: 80%\n",
        "\n",
        "# Fit the column transformer to the training data\n",
        "ct.fit(X_train)\n",
        "\n",
        "# Transform training and test data with normalization (MinMaxScaler) and OneHotEncoder\n",
        "X_train_normal = ct.transform(X_train)\n",
        "X_test_normal = ct.transform(X_test)"
      ],
      "metadata": {
        "id": "MNXjAlGs1J80"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# What does the data look like now?\n",
        "X_train.loc[0], X_train_normal[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpBaaMD31NI0",
        "outputId": "0fd58097-6c0b-4a93-89c2-ccfab3f2a42a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(age                19\n",
              " sex            female\n",
              " bmi              27.9\n",
              " children            0\n",
              " smoker            yes\n",
              " region      southwest\n",
              " Name: 0, dtype: object,\n",
              " array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
              "        1.        , 0.        , 0.        , 1.        , 0.        ,\n",
              "        0.        ]))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare how the shapes have changed\n",
        "X_train.shape, X_train_normal.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOSbEyeP1iY-",
        "outputId": "85016f7f-2dad-49c1-b6c6-c6daaadca013"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1070, 6), (1070, 11))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Beautiful! The data is now normalized and one hot encoded.input_shape\n",
        "Now let's build a neural network model on it and see how it goes !"
      ],
      "metadata": {
        "id": "eAPEEZhyAHcc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a neural network model to fit on the normalized data\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(42)    # to allow reproducibility\n",
        "\n",
        "# 1. Create the model\n",
        "insurance_model_4 = tf.keras.Sequential([\n",
        "                     tf.keras.layers.Dense(100),\n",
        "                     tf.keras.layers.Dense(10),\n",
        "                     tf.keras.layers.Dense(1)                   \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "insurance_model_4.compile(loss=tf.keras.losses.mae,\n",
        "                          optimizer = tf.keras.optimizers.Adam(),\n",
        "                          metrics = [\"mae\"])\n",
        "\n",
        "# 3. Fit the model on the normalized data\n",
        "insurance_model_4.fit(X_train_normal, y_train, epochs =100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GutggUvbAe3D",
        "outputId": "146a89d2-80b9-415c-d0e5-222d2fd54994"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13342.6475 - mae: 13342.6475\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13333.4785 - mae: 13333.4785\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13312.0234 - mae: 13312.0234\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13267.7930 - mae: 13267.7930\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13189.5850 - mae: 13189.5850\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 13066.4502 - mae: 13066.4502\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12888.1953 - mae: 12888.1953\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 12644.6523 - mae: 12644.6523\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 12325.5469 - mae: 12325.5469\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 11925.9658 - mae: 11925.9658\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 11454.3350 - mae: 11454.3350\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10949.8086 - mae: 10949.8086\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 10448.9404 - mae: 10448.9404\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9951.6250 - mae: 9951.6250\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9482.7422 - mae: 9482.7422\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 9066.7461 - mae: 9066.7461\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8721.9854 - mae: 8721.9854\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8441.2002 - mae: 8441.2002\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8227.5117 - mae: 8227.5117\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 8081.9775 - mae: 8081.9775\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7973.8945 - mae: 7973.8945\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7899.1597 - mae: 7899.1597\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7840.3916 - mae: 7840.3916\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7787.9619 - mae: 7787.9619\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7749.2622 - mae: 7749.2622\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7697.9595 - mae: 7697.9595\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7656.0273 - mae: 7656.0273\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7613.4780 - mae: 7613.4780\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7570.9482 - mae: 7570.9482\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7527.4175 - mae: 7527.4175\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7483.5947 - mae: 7483.5947\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7439.4424 - mae: 7439.4424\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7395.0552 - mae: 7395.0552\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7346.8125 - mae: 7346.8125\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7300.0493 - mae: 7300.0493\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7249.8452 - mae: 7249.8452\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7199.5303 - mae: 7199.5303\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7148.4805 - mae: 7148.4805\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7093.6660 - mae: 7093.6660\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 7038.1797 - mae: 7038.1797\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6981.7393 - mae: 6981.7393\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6922.7847 - mae: 6922.7847\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6860.1724 - mae: 6860.1724\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6793.7979 - mae: 6793.7979\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6726.6201 - mae: 6726.6201\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6657.4683 - mae: 6657.4683\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6586.3086 - mae: 6586.3086\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6507.5063 - mae: 6507.5063\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6428.6025 - mae: 6428.6025\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6342.7100 - mae: 6342.7100\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6258.0718 - mae: 6258.0718\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6164.7046 - mae: 6164.7046\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 6068.6748 - mae: 6068.6748\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5970.0981 - mae: 5970.0981\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5862.5625 - mae: 5862.5625\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5753.9531 - mae: 5753.9531\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5638.0942 - mae: 5638.0942\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5519.8687 - mae: 5519.8687\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5401.3198 - mae: 5401.3198\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5277.3506 - mae: 5277.3506\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 5149.7642 - mae: 5149.7642\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 5019.3540 - mae: 5019.3540\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4889.6865 - mae: 4889.6865\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4756.8560 - mae: 4756.8560\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4629.4370 - mae: 4629.4370\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4503.5991 - mae: 4503.5991\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4392.9922 - mae: 4392.9922\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4284.3862 - mae: 4284.3862\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4182.6182 - mae: 4182.6182\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4089.5720 - mae: 4089.5720\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 4003.3901 - mae: 4003.3901\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3929.0093 - mae: 3929.0093\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3866.3110 - mae: 3866.3110\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3813.7144 - mae: 3813.7144\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3773.0317 - mae: 3773.0317\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3744.1995 - mae: 3744.1995\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3719.6870 - mae: 3719.6870\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3702.9109 - mae: 3702.9109\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3691.8792 - mae: 3691.8792\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3682.8350 - mae: 3682.8350\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3676.9763 - mae: 3676.9763\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3673.9492 - mae: 3673.9492\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3667.8452 - mae: 3667.8452\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3664.5757 - mae: 3664.5757\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 3ms/step - loss: 3661.8562 - mae: 3661.8562\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3660.3049 - mae: 3660.3049\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3657.5134 - mae: 3657.5134\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3655.2200 - mae: 3655.2200\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3653.8831 - mae: 3653.8831\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3652.0195 - mae: 3652.0195\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3648.9990 - mae: 3648.9990\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3648.4463 - mae: 3648.4463\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3646.2297 - mae: 3646.2297\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3644.4377 - mae: 3644.4377\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3645.8772 - mae: 3645.8772\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3642.2573 - mae: 3642.2573\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3640.1184 - mae: 3640.1184\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3638.0649 - mae: 3638.0649\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3637.2051 - mae: 3637.2051\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 2ms/step - loss: 3636.1707 - mae: 3636.1707\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f49847dc990>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the insurance model trained on normalized data\n",
        "insurance_model_4.evaluate(X_test_normal, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFloWk42At0u",
        "outputId": "71e2b8ea-1718-4399-a36f-298a7b25d537"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 3438.7844 - mae: 3438.7844\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3438.784423828125, 3438.784423828125]"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# insurance_model_2 results\n",
        "# 9/9 [==============================] - 0s 2ms/step - loss: 4924.3477 - mae: 4924.3477\n",
        "# [4924.34765625, 4924.34765625]"
      ],
      "metadata": {
        "id": "Gx67FxLsAvqW"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insurance_model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkeCrALiCrBj",
        "outputId": "90111a9b-56c4-48b7-b2ac-5d8175daad39"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_14 (Dense)            (None, 100)               1200      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,221\n",
            "Trainable params: 2,221\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boston Housing \n",
        "\n",
        "Dataset taken from the StaLib library which is maintained at Carnegie Mellon University.\n"
      ],
      "metadata": {
        "id": "j34tFdXrCtwb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample contains 13 attributes of houses at different locations around the Boston suburbs in the late 1970s. Targets are the median values of the hosues at a location (in k$).\n",
        "\n",
        "The attributes themsevles are define in the StatLib Website:\n",
        ">The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
        " prices and the demand for clean air', J. Environ. Economics & Management,\n",
        " vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
        " ...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
        " pages 244-261 of the latter.\n",
        "\n",
        " >Variables in order:\n",
        " * **CRIM** -     per capita crime rate by town\n",
        " * **ZN** -       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        " * **INDUS** -    proportion of non-retail business acres per town\n",
        " * **CHAS** -     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        " * **NOX** -      nitric oxides concentration (parts per 10 million)\n",
        " * **RM** -       average number of rooms per dwelling\n",
        " * **AGE** -      proportion of owner-occupied units built prior to 1940\n",
        " * **DIS** -      weighted distances to five Boston employment centres\n",
        " * **RAD** -      index of accessibility to radial highways\n",
        " * **TAX** -      full-value property-tax rate per `$10,000`\n",
        " * **PTRATIO** -  pupil-teacher ratio by town\n",
        " * **B** -        1000(Bk - 0.63)^2 where Bk is the proportion of Black people by town\n",
        " * **LSTAT** -    % lower status of the population\n",
        " * **MEDV** -     Median value of owner-occupied homes in $1000's"
      ],
      "metadata": {
        "id": "W-NPScmu4wu2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "wk-f0PrL5Q-l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import data\n",
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data(path = 'boston_housing.npz', test_split=0.2, seed=42)   # train: 80%, test: 20%; reproducibility"
      ],
      "metadata": {
        "id": "KpCo3Zn68hFr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the shape of the imported data\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEpGdbZZ9Al7",
        "outputId": "4f4a5185-7b8f-4c50-d144-76ccf203fee4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((404, 13), (102, 13), (404,), (102,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLGOtHGuE11J",
        "outputId": "b5af47a6-ff6a-483a-f725-501310378b99"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9.1780e-02, 0.0000e+00, 4.0500e+00, 0.0000e+00, 5.1000e-01,\n",
              "       6.4160e+00, 8.4100e+01, 2.6463e+00, 5.0000e+00, 2.9600e+02,\n",
              "       1.6600e+01, 3.9550e+02, 9.0400e+00])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is a `numpy` array format and is normalized."
      ],
      "metadata": {
        "id": "W7humXun_4L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "tf.random.set_seed(42)   # allow for reproducibility\n",
        "\n",
        "# 1. Create the model (5 layers with 200, 20, 150, 100, 1 hidden units, respectively)\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(200),\n",
        "        tf.keras.layers.Dense(200),\n",
        "        tf.keras.layers.Dense(150),\n",
        "        tf.keras.layers.Dense(100),\n",
        "        tf.keras.layers.Dense(1)                     \n",
        "])\n",
        "\n",
        "# 2. Compile the model\n",
        "model.compile(loss = tf.keras.losses.mae,\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = ['mae'])\n",
        "\n",
        "# 3. Fit the model (time duration of 300 epochs)\n",
        "history = model.fit(X_train, y_train, epochs=300)         "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzyZz90e_5Ar",
        "outputId": "850568e3-1817-4586-b248-e9f1800bf25d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "13/13 [==============================] - 1s 5ms/step - loss: 95.6416 - mae: 95.6416\n",
            "Epoch 2/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 15.5989 - mae: 15.5989\n",
            "Epoch 3/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 8.6769 - mae: 8.6769\n",
            "Epoch 4/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.5622 - mae: 7.5622\n",
            "Epoch 5/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 7.1922 - mae: 7.1922\n",
            "Epoch 6/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.3219 - mae: 6.3219\n",
            "Epoch 7/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.7137 - mae: 6.7137\n",
            "Epoch 8/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.3261 - mae: 6.3261\n",
            "Epoch 9/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7.6760 - mae: 7.6760\n",
            "Epoch 10/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 8.2790 - mae: 8.2790\n",
            "Epoch 11/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 7.5814 - mae: 7.5814\n",
            "Epoch 12/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6.1497 - mae: 6.1497\n",
            "Epoch 13/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6.8925 - mae: 6.8925\n",
            "Epoch 14/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.6252 - mae: 6.6252\n",
            "Epoch 15/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.0204 - mae: 6.0204\n",
            "Epoch 16/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.9461 - mae: 5.9461\n",
            "Epoch 17/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.0552 - mae: 6.0552\n",
            "Epoch 18/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 8.7383 - mae: 8.7383\n",
            "Epoch 19/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.0990 - mae: 6.0990\n",
            "Epoch 20/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.0742 - mae: 6.0742\n",
            "Epoch 21/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 6.0414 - mae: 6.0414\n",
            "Epoch 22/300\n",
            "13/13 [==============================] - 0s 7ms/step - loss: 6.3905 - mae: 6.3905\n",
            "Epoch 23/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 7.1209 - mae: 7.1209\n",
            "Epoch 24/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5.9498 - mae: 5.9498\n",
            "Epoch 25/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 6.0166 - mae: 6.0166\n",
            "Epoch 26/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 5.7096 - mae: 5.7096\n",
            "Epoch 27/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.9713 - mae: 5.9713\n",
            "Epoch 28/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.0495 - mae: 6.0495\n",
            "Epoch 29/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.4829 - mae: 6.4829\n",
            "Epoch 30/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.9871 - mae: 5.9871\n",
            "Epoch 31/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7400 - mae: 5.7400\n",
            "Epoch 32/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6346 - mae: 5.6346\n",
            "Epoch 33/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4856 - mae: 5.4856\n",
            "Epoch 34/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.0210 - mae: 6.0210\n",
            "Epoch 35/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.8396 - mae: 5.8396\n",
            "Epoch 36/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.1415 - mae: 6.1415\n",
            "Epoch 37/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.5686 - mae: 5.5686\n",
            "Epoch 38/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.4294 - mae: 5.4294\n",
            "Epoch 39/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3107 - mae: 5.3107\n",
            "Epoch 40/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4110 - mae: 5.4110\n",
            "Epoch 41/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.1905 - mae: 6.1905\n",
            "Epoch 42/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.0617 - mae: 6.0617\n",
            "Epoch 43/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7706 - mae: 5.7706\n",
            "Epoch 44/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.7031 - mae: 5.7031\n",
            "Epoch 45/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.4331 - mae: 5.4331\n",
            "Epoch 46/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.5578 - mae: 5.5578\n",
            "Epoch 47/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.7635 - mae: 5.7635\n",
            "Epoch 48/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7261 - mae: 5.7261\n",
            "Epoch 49/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.5282 - mae: 5.5282\n",
            "Epoch 50/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6309 - mae: 5.6309\n",
            "Epoch 51/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2450 - mae: 5.2450\n",
            "Epoch 52/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.1148 - mae: 6.1148\n",
            "Epoch 53/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7079 - mae: 5.7079\n",
            "Epoch 54/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3353 - mae: 5.3353\n",
            "Epoch 55/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2361 - mae: 5.2361\n",
            "Epoch 56/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2498 - mae: 5.2498\n",
            "Epoch 57/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4700 - mae: 5.4700\n",
            "Epoch 58/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3339 - mae: 5.3339\n",
            "Epoch 59/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3895 - mae: 5.3895\n",
            "Epoch 60/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.3970 - mae: 5.3970\n",
            "Epoch 61/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0362 - mae: 5.0362\n",
            "Epoch 62/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1850 - mae: 5.1850\n",
            "Epoch 63/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9453 - mae: 4.9453\n",
            "Epoch 64/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1657 - mae: 5.1657\n",
            "Epoch 65/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0569 - mae: 5.0569\n",
            "Epoch 66/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1671 - mae: 5.1671\n",
            "Epoch 67/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3315 - mae: 5.3315\n",
            "Epoch 68/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 5.2022 - mae: 5.2022\n",
            "Epoch 69/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9474 - mae: 4.9474\n",
            "Epoch 70/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8188 - mae: 4.8188\n",
            "Epoch 71/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9177 - mae: 4.9177\n",
            "Epoch 72/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7716 - mae: 4.7716\n",
            "Epoch 73/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9094 - mae: 4.9094\n",
            "Epoch 74/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7717 - mae: 4.7717\n",
            "Epoch 75/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9760 - mae: 4.9760\n",
            "Epoch 76/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7950 - mae: 4.7950\n",
            "Epoch 77/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.6677 - mae: 5.6677\n",
            "Epoch 78/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2260 - mae: 5.2260\n",
            "Epoch 79/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 4.9404 - mae: 4.9404\n",
            "Epoch 80/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1695 - mae: 5.1695\n",
            "Epoch 81/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0636 - mae: 5.0636\n",
            "Epoch 82/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8237 - mae: 4.8237\n",
            "Epoch 83/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7657 - mae: 4.7657\n",
            "Epoch 84/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1047 - mae: 5.1047\n",
            "Epoch 85/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.5308 - mae: 5.5308\n",
            "Epoch 86/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0155 - mae: 5.0155\n",
            "Epoch 87/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0192 - mae: 5.0192\n",
            "Epoch 88/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9293 - mae: 4.9293\n",
            "Epoch 89/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8602 - mae: 4.8602\n",
            "Epoch 90/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0446 - mae: 5.0446\n",
            "Epoch 91/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.2620 - mae: 6.2620\n",
            "Epoch 92/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2720 - mae: 5.2720\n",
            "Epoch 93/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0549 - mae: 5.0549\n",
            "Epoch 94/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6809 - mae: 4.6809\n",
            "Epoch 95/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6231 - mae: 4.6231\n",
            "Epoch 96/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7098 - mae: 5.7098\n",
            "Epoch 97/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 6.8946 - mae: 6.8946\n",
            "Epoch 98/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4293 - mae: 5.4293\n",
            "Epoch 99/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6838 - mae: 4.6838\n",
            "Epoch 100/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1718 - mae: 5.1718\n",
            "Epoch 101/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.5614 - mae: 5.5614\n",
            "Epoch 102/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.7388 - mae: 5.7388\n",
            "Epoch 103/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.4520 - mae: 5.4520\n",
            "Epoch 104/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.5411 - mae: 5.5411\n",
            "Epoch 105/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8349 - mae: 4.8349\n",
            "Epoch 106/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8145 - mae: 4.8145\n",
            "Epoch 107/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4946 - mae: 4.4946\n",
            "Epoch 108/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6472 - mae: 4.6472\n",
            "Epoch 109/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0038 - mae: 5.0038\n",
            "Epoch 110/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5527 - mae: 4.5527\n",
            "Epoch 111/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9715 - mae: 4.9715\n",
            "Epoch 112/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.3007 - mae: 5.3007\n",
            "Epoch 113/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7218 - mae: 4.7218\n",
            "Epoch 114/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4980 - mae: 4.4980\n",
            "Epoch 115/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6827 - mae: 4.6827\n",
            "Epoch 116/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5726 - mae: 4.5726\n",
            "Epoch 117/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7908 - mae: 4.7908\n",
            "Epoch 118/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5545 - mae: 4.5545\n",
            "Epoch 119/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6980 - mae: 4.6980\n",
            "Epoch 120/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5942 - mae: 4.5942\n",
            "Epoch 121/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6677 - mae: 4.6677\n",
            "Epoch 122/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8822 - mae: 4.8822\n",
            "Epoch 123/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8486 - mae: 4.8486\n",
            "Epoch 124/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4416 - mae: 4.4416\n",
            "Epoch 125/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2741 - mae: 4.2741\n",
            "Epoch 126/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6422 - mae: 4.6422\n",
            "Epoch 127/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6263 - mae: 4.6263\n",
            "Epoch 128/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6148 - mae: 4.6148\n",
            "Epoch 129/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3544 - mae: 4.3544\n",
            "Epoch 130/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6760 - mae: 4.6760\n",
            "Epoch 131/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.2202 - mae: 5.2202\n",
            "Epoch 132/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5795 - mae: 4.5795\n",
            "Epoch 133/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8683 - mae: 4.8683\n",
            "Epoch 134/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0730 - mae: 5.0730\n",
            "Epoch 135/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8273 - mae: 4.8273\n",
            "Epoch 136/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.0065 - mae: 5.0065\n",
            "Epoch 137/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.1660 - mae: 5.1660\n",
            "Epoch 138/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0057 - mae: 5.0057\n",
            "Epoch 139/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5432 - mae: 4.5432\n",
            "Epoch 140/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5475 - mae: 4.5475\n",
            "Epoch 141/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5476 - mae: 4.5476\n",
            "Epoch 142/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5047 - mae: 4.5047\n",
            "Epoch 143/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9414 - mae: 4.9414\n",
            "Epoch 144/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.2662 - mae: 5.2662\n",
            "Epoch 145/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0108 - mae: 5.0108\n",
            "Epoch 146/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3673 - mae: 4.3673\n",
            "Epoch 147/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4223 - mae: 4.4223\n",
            "Epoch 148/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3712 - mae: 4.3712\n",
            "Epoch 149/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5548 - mae: 4.5548\n",
            "Epoch 150/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4692 - mae: 4.4692\n",
            "Epoch 151/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2082 - mae: 4.2082\n",
            "Epoch 152/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3511 - mae: 4.3511\n",
            "Epoch 153/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4618 - mae: 4.4618\n",
            "Epoch 154/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3224 - mae: 4.3224\n",
            "Epoch 155/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9471 - mae: 4.9471\n",
            "Epoch 156/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6512 - mae: 4.6512\n",
            "Epoch 157/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2240 - mae: 4.2240\n",
            "Epoch 158/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7752 - mae: 4.7752\n",
            "Epoch 159/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6596 - mae: 4.6596\n",
            "Epoch 160/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2856 - mae: 4.2856\n",
            "Epoch 161/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5804 - mae: 4.5804\n",
            "Epoch 162/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7792 - mae: 4.7792\n",
            "Epoch 163/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.9781 - mae: 4.9781\n",
            "Epoch 164/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5799 - mae: 4.5799\n",
            "Epoch 165/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5203 - mae: 4.5203\n",
            "Epoch 166/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1376 - mae: 4.1376\n",
            "Epoch 167/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5029 - mae: 4.5029\n",
            "Epoch 168/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7947 - mae: 4.7947\n",
            "Epoch 169/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2660 - mae: 4.2660\n",
            "Epoch 170/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.8228 - mae: 4.8228\n",
            "Epoch 171/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9133 - mae: 4.9133\n",
            "Epoch 172/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 5.0498 - mae: 5.0498\n",
            "Epoch 173/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.5031 - mae: 5.5031\n",
            "Epoch 174/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.9650 - mae: 4.9650\n",
            "Epoch 175/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7348 - mae: 4.7348\n",
            "Epoch 176/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 5.3164 - mae: 5.3164\n",
            "Epoch 177/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8209 - mae: 4.8209\n",
            "Epoch 178/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4017 - mae: 4.4017\n",
            "Epoch 179/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6967 - mae: 4.6967\n",
            "Epoch 180/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4352 - mae: 4.4352\n",
            "Epoch 181/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3864 - mae: 4.3864\n",
            "Epoch 182/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4418 - mae: 4.4418\n",
            "Epoch 183/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8378 - mae: 4.8378\n",
            "Epoch 184/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.8008 - mae: 4.8008\n",
            "Epoch 185/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2200 - mae: 4.2200\n",
            "Epoch 186/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3151 - mae: 4.3151\n",
            "Epoch 187/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5120 - mae: 4.5120\n",
            "Epoch 188/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4864 - mae: 4.4864\n",
            "Epoch 189/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2428 - mae: 4.2428\n",
            "Epoch 190/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4948 - mae: 4.4948\n",
            "Epoch 191/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2268 - mae: 4.2268\n",
            "Epoch 192/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1860 - mae: 4.1860\n",
            "Epoch 193/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3617 - mae: 4.3617\n",
            "Epoch 194/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5445 - mae: 4.5445\n",
            "Epoch 195/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1583 - mae: 4.1583\n",
            "Epoch 196/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2125 - mae: 4.2125\n",
            "Epoch 197/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1771 - mae: 4.1771\n",
            "Epoch 198/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2117 - mae: 4.2117\n",
            "Epoch 199/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0825 - mae: 4.0825\n",
            "Epoch 200/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.1891 - mae: 4.1891\n",
            "Epoch 201/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1673 - mae: 4.1673\n",
            "Epoch 202/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3206 - mae: 4.3206\n",
            "Epoch 203/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5868 - mae: 4.5868\n",
            "Epoch 204/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2607 - mae: 4.2607\n",
            "Epoch 205/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0537 - mae: 4.0537\n",
            "Epoch 206/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2703 - mae: 4.2703\n",
            "Epoch 207/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0290 - mae: 4.0290\n",
            "Epoch 208/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1380 - mae: 4.1380\n",
            "Epoch 209/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1634 - mae: 4.1634\n",
            "Epoch 210/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2036 - mae: 4.2036\n",
            "Epoch 211/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4334 - mae: 4.4334\n",
            "Epoch 212/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3069 - mae: 4.3069\n",
            "Epoch 213/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2108 - mae: 4.2108\n",
            "Epoch 214/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.4054 - mae: 4.4054\n",
            "Epoch 215/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3315 - mae: 4.3315\n",
            "Epoch 216/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0598 - mae: 4.0598\n",
            "Epoch 217/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4140 - mae: 4.4140\n",
            "Epoch 218/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2109 - mae: 4.2109\n",
            "Epoch 219/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4263 - mae: 4.4263\n",
            "Epoch 220/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7120 - mae: 4.7120\n",
            "Epoch 221/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5031 - mae: 4.5031\n",
            "Epoch 222/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5977 - mae: 4.5977\n",
            "Epoch 223/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7256 - mae: 4.7256\n",
            "Epoch 224/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5207 - mae: 4.5207\n",
            "Epoch 225/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0861 - mae: 4.0861\n",
            "Epoch 226/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0006 - mae: 4.0006\n",
            "Epoch 227/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1312 - mae: 4.1312\n",
            "Epoch 228/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9995 - mae: 3.9995\n",
            "Epoch 229/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9518 - mae: 3.9518\n",
            "Epoch 230/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0000 - mae: 4.0000\n",
            "Epoch 231/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8919 - mae: 4.8919\n",
            "Epoch 232/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.5518 - mae: 4.5518\n",
            "Epoch 233/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6870 - mae: 4.6870\n",
            "Epoch 234/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.7395 - mae: 4.7395\n",
            "Epoch 235/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3844 - mae: 4.3844\n",
            "Epoch 236/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3707 - mae: 4.3707\n",
            "Epoch 237/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0383 - mae: 4.0383\n",
            "Epoch 238/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1589 - mae: 4.1589\n",
            "Epoch 239/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3549 - mae: 4.3549\n",
            "Epoch 240/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1713 - mae: 4.1713\n",
            "Epoch 241/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1815 - mae: 4.1815\n",
            "Epoch 242/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.2620 - mae: 4.2620\n",
            "Epoch 243/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6366 - mae: 4.6366\n",
            "Epoch 244/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0447 - mae: 4.0447\n",
            "Epoch 245/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1017 - mae: 4.1017\n",
            "Epoch 246/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.8938 - mae: 3.8938\n",
            "Epoch 247/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2034 - mae: 4.2034\n",
            "Epoch 248/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9596 - mae: 3.9596\n",
            "Epoch 249/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7845 - mae: 3.7845\n",
            "Epoch 250/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.4504 - mae: 4.4504\n",
            "Epoch 251/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0933 - mae: 4.0933\n",
            "Epoch 252/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9389 - mae: 3.9389\n",
            "Epoch 253/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.2332 - mae: 4.2332\n",
            "Epoch 254/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.6568 - mae: 4.6568\n",
            "Epoch 255/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2393 - mae: 4.2393\n",
            "Epoch 256/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.2893 - mae: 4.2893\n",
            "Epoch 257/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2181 - mae: 4.2181\n",
            "Epoch 258/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4770 - mae: 4.4770\n",
            "Epoch 259/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.5503 - mae: 4.5503\n",
            "Epoch 260/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.8233 - mae: 4.8233\n",
            "Epoch 261/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6596 - mae: 4.6596\n",
            "Epoch 262/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.6836 - mae: 4.6836\n",
            "Epoch 263/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0679 - mae: 4.0679\n",
            "Epoch 264/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.3678 - mae: 4.3678\n",
            "Epoch 265/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1161 - mae: 4.1161\n",
            "Epoch 266/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9458 - mae: 3.9458\n",
            "Epoch 267/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4051 - mae: 4.4051\n",
            "Epoch 268/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1547 - mae: 4.1547\n",
            "Epoch 269/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9783 - mae: 3.9783\n",
            "Epoch 270/300\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 4.3867 - mae: 4.3867\n",
            "Epoch 271/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8289 - mae: 3.8289\n",
            "Epoch 272/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1123 - mae: 4.1123\n",
            "Epoch 273/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7205 - mae: 3.7205\n",
            "Epoch 274/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7777 - mae: 3.7777\n",
            "Epoch 275/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1356 - mae: 4.1356\n",
            "Epoch 276/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9818 - mae: 3.9818\n",
            "Epoch 277/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.9115 - mae: 3.9115\n",
            "Epoch 278/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4542 - mae: 4.4542\n",
            "Epoch 279/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8984 - mae: 3.8984\n",
            "Epoch 280/300\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 3.9156 - mae: 3.9156\n",
            "Epoch 281/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.7365 - mae: 4.7365\n",
            "Epoch 282/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8490 - mae: 3.8490\n",
            "Epoch 283/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.2113 - mae: 4.2113\n",
            "Epoch 284/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0127 - mae: 4.0127\n",
            "Epoch 285/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1838 - mae: 4.1838\n",
            "Epoch 286/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9109 - mae: 3.9109\n",
            "Epoch 287/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7775 - mae: 3.7775\n",
            "Epoch 288/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.6404 - mae: 3.6404\n",
            "Epoch 289/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.7319 - mae: 3.7319\n",
            "Epoch 290/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8478 - mae: 3.8478\n",
            "Epoch 291/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.1955 - mae: 4.1955\n",
            "Epoch 292/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.0784 - mae: 4.0784\n",
            "Epoch 293/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8463 - mae: 3.8463\n",
            "Epoch 294/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.8500 - mae: 3.8500\n",
            "Epoch 295/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.0462 - mae: 4.0462\n",
            "Epoch 296/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7579 - mae: 3.7579\n",
            "Epoch 297/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.1257 - mae: 4.1257\n",
            "Epoch 298/300\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 3.7568 - mae: 3.7568\n",
            "Epoch 299/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 3.9175 - mae: 3.9175\n",
            "Epoch 300/300\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 4.3548 - mae: 4.3548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "model.evaluate(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nirFFIDtFsaI",
        "outputId": "90448c6e-bb77-48a1-9c91-2ba073a0ac5b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 9ms/step - loss: 3.7630 - mae: 3.7630\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.76304030418396, 3.76304030418396]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the loss vs epoch to see the model's learning progress\n",
        "pd.DataFrame(history.history).plot()\n",
        "plt.xlabel(\"loss\")\n",
        "plt.ylabel(\"epochs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "CQHlBvXXHdE2",
        "outputId": "a23889dc-fb33-4d0b-f08e-343d8072fa1c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7uTFZ7n7HwHl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}